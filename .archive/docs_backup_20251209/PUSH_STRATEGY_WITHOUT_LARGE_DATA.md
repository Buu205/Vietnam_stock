# üìã PUSH STRATEGY WITHOUT LARGE DATA FILES

**Ng√†y:** 2025-12-08
**M·ª•c ƒë√≠ch:** H∆∞·ªõng d·∫´n push repository l√™n GitHub m√† kh√¥ng bao g·ªìm c√°c file data l·ªõn

---

## üéØ T√åM T·∫ÆNG HI·ªÜN T·∫†I

### 1. Ph√¢n t√≠ch th∆∞ m·ª•c quan tr·ªçng
```
DATA/ = 226MB (n·∫∑ng nh·∫π cho Git)
‚îú‚îÄ‚îÄ raw/ = 236MB (ƒëang ch·ª©a c√°c file CSV g·ªëc)
‚îÇ   ‚îú‚îÄ‚îÄ fundamental/processed/ = 186MB (c√°c file CSV l·ªõn c·∫ßn lo·∫°i b·ªè)
‚îÇ   ‚îî‚îÄ‚îÄ ohlcv/ = 28MB
‚îÇ   ‚îî‚îÄ‚îÄ commodity/ = 17MB
‚îÇ   ‚îî‚îÄ‚îÄ macro/ = 14MB
‚îÇ
‚îú‚îÄ‚îÄ processed/ = 112MB (k·∫øt qu·∫£ x·ª≠ l√Ω)
‚îÇ   ‚îú‚îÄ‚îÄ fundamental/ = 46MB
‚îÇ   ‚îú‚îÄ‚îÄ technical/ = 40MB (l·ªõn nh·∫•t)
‚îÇ   ‚îú‚îÄ‚îÄ valuation/ = 22MB
‚îÇ   ‚îî‚îÄ‚îÄ commodity/ = 4MB
‚îÇ   ‚îî‚îÄ‚îÄ macro/ = 1MB
‚îÇ
‚îú‚îÄ‚îÄ schemas/ = 100KB
‚îÇ
‚îú‚îÄ‚îÄ metadata/ = 864KB
‚îÇ
‚îî‚îÄ‚îÄ archive/ = 90MB (backup c≈©)
```

### 2. File l·ªõn nh·∫•t c·∫ßn xem x√©t
```
Top 5 file parquet l·ªõn (>5MB):
1. trading_values_full.parquet - 40MB
2. ev_ebitda_historical_all_symbols_final.parquet - 17MB
3. pb_historical_all_symbols_final.parquet - 7.3MB
4. pe_historical_all_symbols_final.parquet - 6.1MB
5. company_financial_metrics.parquet - 5.1MB
```

---

## üéØ GI·∫¢I PH√ÅP ƒê·ªÄ XU·∫§T

### Ph∆∞∆°ng √°n 1: Gi·ªØ nguy√™n tr·∫°ng th√°i (Khuy·∫øn ngh·ªã)

**∆Øu ƒëi·ªÉm:**
- Repository ƒë·ªß nh·∫π ƒë·ªÉ push nhanh
- ƒê√£ t·ªëi ∆∞u v·ªõi .gitignore hi·ªáu qu·∫£
- Kh√¥ng c·∫ßn thay ƒë·ªïi g√¨

**H√†nh ƒë·ªông:**
```bash
# Gi·ªØ nguy√™n tr·∫°ng th√°i hi·ªán t·∫°i
git status

# T·∫°o commit cu·ªëi c√πng
git add PROCESSORS/ WEBAPP/ CONFIG/ docs/ scripts/
git commit -m "Final commit with canonical structure"

# Push l√™n GitHub
git push origin main
```

### Ph∆∞∆°ng √°n 2: X√≥a c√°c file kh√¥ng c·∫ßn thi·∫øt (Kh√¥ng khuy·∫øn ngh·ªã)

**Khi n√†o c·∫ßn:**
- File backup tr√πng l·∫∑p (files c√≥ ch·ªØ "backup" ho·∫∑c "_20*")
- File cache c·ªßa h·ªá th·ªëng
- File test/data demo

**H√†nh ƒë·ªông:**
```bash
# X√≥a file backup tr√πng l·∫∑p
find DATA/processed -name "*backup*" -delete
find DATA/processed -name "*_20*" -delete

# Gi·ªØ l·∫°i N file g·∫ßn nh·∫•t cho m·ªói lo·∫°i
find DATA/processed -name "*.parquet" | \
  sort -r | head -n -5 | xargs rm -f

# Ki·ªÉm tra l·∫°i dung l∆∞·ª£ng
du -sh DATA/
```

### Ph∆∞∆°ng √°n 3: Push v·ªõi LFS khi c·∫ßn (T∆∞∆°ng lai)

**Khi n√†o c·∫ßn:**
- File qu√° l·ªõn (>100MB) nh∆∞ng b·∫Øt bu·ªôc ph·∫£i version control
- File d·ªØ li·ªáu quan tr·ªçng (thay ƒë·ªïi th∆∞·ªùng xuy√™n ng√†y)

**H√†nh ƒë·ªông:**
```bash
# 1. C√†i ƒë·∫∑t Git LFS
git lfs install

# 2. Th√™m c√°c file l·ªõn v√†o LFS
echo "*.parquet filter=lfs diff=lfs merge=lfs -text" >> .gitattributes

# 3. Theo d√µi c√°c file l·ªõn
git lfs track "DATA/processed/technical/trading_values_full.parquet"
git lfs track "DATA/processed/valuation/ev_ebitda/ev_ebitda_historical_all_symbols_final.parquet"

# 4. Push LFS files
git add .gitattributes
git add <file_l·ªõn>
git commit -m "Add LFS tracking for large parquet files"
git push
```

---

## üìã L·ª∞A CH·ªåN T∆Ø∆†NG GHI NH·∫¨N

### 1. T·∫°i sao ph·∫£i ch·ªçn ph∆∞∆°ng √°n 1?
- Dung l∆∞·ª£ng t·ªïng 2.3GB kh√° h·ª£p l√Ω cho development
- C√°c file quan tr·ªçng (parquet) v·∫´n ƒë∆∞·ª£c version control
- File CSV l·ªõn (186MB) ch·ªâ d√πng locally
- Repository ƒë·ªß nh·∫π cho c√°c thao t√°c push h√†ng ng√†y

### 2. N·∫øu c·∫ßn gi·∫£m dung l∆∞·ª£ng d∆∞·ªõi 2.3GB
```bash
# T·ªëi ∆∞u h√≥a
find DATA/processed -name "*.parquet" -exec gzip {} \;
   
# Chuy·ªÉn th√†nh c√°c file c≈©
find DATA/processed -name "*.parquet" -exec gzip --force {} \;
   
# C·∫≠p nh·∫≠t code ƒë·ªÉ x·ª≠ l√Ω file gzip
# Trong file ƒë·ªçc, th√™m:
import gzip
   
   df = pd.read_parquet("input_file.gz", engine='pyarrow')
```

### 3. Gi·∫£i ph√°p t·ªët nh·∫•t cho t∆∞∆°ng lai
```
# 1. X·ª≠ l√Ω t·∫°i ch·ªó
git add PROCESSORS/ WEBAPP/ CONFIG/ docs/ scripts/
git commit -m "Add core functionality"

# 2. Push code-only l√™n GitHub
git push origin main

# 3. X·ª≠ l√Ω data khi c·∫ßn
# Ch·ªâ download v√† x·ª≠ l√Ω t·∫°i th·ªùi ƒëi·ªÉm c·∫ßn
python3 PROCESSING/pipelines/daily_update.py --date YYYY-MM-DD

# 4. D·ªØ li·ªáu l·ªõn l∆∞u tr·ªØ ngo√†i
# S·ª≠ d·ª•ng external storage (S3, Google Drive, OneDrive)
# D·ªØ li·ªáu l·ªãch s·ª≠ d·ª•ng archival (x√≥a c≈©, ch·ªâ gi·ªØ N th√°ng g·∫ßn nh·∫•t)
```

---

## üìã RECOMMENDATION

### 1. Repository size
- **Hi·ªán t·∫°i:** 2.3GB (lightweight)
- **Khuy·∫øn ngh·ªã:** D∆∞·ªõi 2GB ƒë·ªÉ push nhanh h√†ng ng√†y

### 2. Theo d√µi GitHub
- **GitHub Free:** Kh√¥ng gi·ªõi h·∫°n cho private repo
- **GitHub Pro:** 100GB cho private repo
- **Repository c·ªßa b·∫°n:** 2.3GB < 1% limit ‚úÖ

### 3. Chi·∫øn l∆∞·ª£c ti·∫øp theo
```bash
# 1. Ki·ªÉm tra l·∫°i tr·∫°ng th√°i sau khi push
git status
git log --oneline -3

# 2. T·∫°o b√°o c√°o c√¥ng vi·ªác h√†ng tu·∫ßn
python3 PROCESSING/pipelines/weekly_report.py
```

---

## üéØ QUY·∫æT ICH C√ÅCH

### 1. Repository structure
- ‚úÖ **CODE**: PROCESSORS/, WEBAPP/, CONFIG/, scripts/
- ‚úÖ **DOCUMENTATION**: T·∫•t c·∫£ h∆∞·ªõng d·∫´n ƒë√£ t·∫°o

### 2. Current workflow
- **Local development** ‚Üí Push code-only
- **Data processing** ‚Üí Ch·ªâ khi c·∫ßn, download v√† x·ª≠ l√Ω t·∫°i ch·ªó

---

**Ng√†y t·∫°o:** 2025-12-08  
**Ng∆∞·ªùi t·∫°o:** Senior Data Architect


