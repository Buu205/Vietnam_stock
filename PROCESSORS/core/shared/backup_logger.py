#!/usr/bin/env python3
"""
Backup Logger Module
Qu·∫£n l√Ω backup v√† logging cho c√°c script c·∫≠p nh·∫≠t d·ªØ li·ªáu trong data_processor
"""

import logging
import shutil
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any
import json
import pandas as pd

logger = logging.getLogger(__name__)


class BackupLogger:
    """Qu·∫£n l√Ω backup v√† logging cho c√°c file d·ªØ li·ªáu."""
    
    def __init__(self, log_dir: Optional[Path] = None):
        """
        Kh·ªüi t·∫°o BackupLogger.
        
        Args:
            log_dir: Th∆∞ m·ª•c l∆∞u log backup (m·∫∑c ƒë·ªãnh: data_processor/logs/backup)
        """
        if log_dir is None:
            # Default to data_processor/logs/backup
            current_file = Path(__file__)
            log_dir = current_file.parent.parent / "logs" / "backup"
        
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # Log file path
        self.log_file = self.log_dir / f"backup_log_{datetime.now().strftime('%Y%m')}.json"
        
        logger.info(f"BackupLogger initialized. Log directory: {self.log_dir}")
    
    def create_backup(self, 
                     source_file: Path, 
                     backup_suffix: Optional[str] = None,
                     keep_latest_only: bool = True) -> Optional[Path]:
        """
        T·∫°o backup cho file v√† log l·∫°i.
        
        Args:
            source_file: ƒê∆∞·ªùng d·∫´n file c·∫ßn backup
            backup_suffix: H·∫≠u t·ªë cho file backup (m·∫∑c ƒë·ªãnh: timestamp)
            keep_latest_only: N·∫øu True, ch·ªâ gi·ªØ l·∫°i backup m·ªõi nh·∫•t, x√≥a c√°c b·∫£n c≈©
        
        Returns:
            ƒê∆∞·ªùng d·∫´n file backup ƒë√£ t·∫°o ho·∫∑c None n·∫øu l·ªói
        """
        try:
            source_file = Path(source_file)
            
            if not source_file.exists():
                logger.warning(f"Source file does not exist: {source_file}")
                return None
            
            # T·∫°o t√™n file backup
            if backup_suffix is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_suffix = f"backup_{timestamp}"
            
            # X√°c ƒë·ªãnh extension
            if source_file.suffix:
                backup_path = source_file.parent / f"{source_file.stem}_{backup_suffix}{source_file.suffix}"
            else:
                backup_path = source_file.parent / f"{source_file.name}_{backup_suffix}"
            
            # N·∫øu keep_latest_only, x√≥a c√°c backup c≈© c√πng pattern
            if keep_latest_only:
                self._cleanup_old_backups(source_file, backup_path)
            
            # Copy file
            shutil.copy2(source_file, backup_path)
            
            # L·∫•y th√¥ng tin file
            file_size = source_file.stat().st_size
            backup_size = backup_path.stat().st_size
            
            # Log backup
            backup_info = {
                "timestamp": datetime.now().isoformat(),
                "source_file": str(source_file),
                "backup_file": str(backup_path),
                "source_size_bytes": file_size,
                "backup_size_bytes": backup_size,
                "source_size_mb": round(file_size / 1024 / 1024, 2),
                "backup_size_mb": round(backup_size / 1024 / 1024, 2),
                "status": "success"
            }
            
            self._log_backup(backup_info)
            
            logger.info(f"‚úÖ Backup created: {backup_path.name} ({backup_info['backup_size_mb']} MB)")
            
            return backup_path
            
        except Exception as e:
            logger.error(f"‚ùå Error creating backup for {source_file}: {e}")
            backup_info = {
                "timestamp": datetime.now().isoformat(),
                "source_file": str(source_file),
                "backup_file": None,
                "status": "failed",
                "error": str(e)
            }
            self._log_backup(backup_info)
            return None
    
    def _cleanup_old_backups(self, source_file: Path, new_backup: Path) -> None:
        """
        X√≥a c√°c file backup c≈© c√πng pattern, ch·ªâ gi·ªØ l·∫°i file m·ªõi nh·∫•t.
        
        Args:
            source_file: File g·ªëc
            new_backup: File backup m·ªõi s·∫Ω ƒë∆∞·ª£c t·∫°o
        """
        try:
            # T√¨m pattern backup (v√≠ d·ª•: filename_backup_*.ext)
            source_stem = source_file.stem
            source_ext = source_file.suffix
            
            # T√¨m t·∫•t c·∫£ file backup c√πng pattern
            backup_patterns = [
                f"{source_stem}_backup_*{source_ext}",
                f"{source_stem}.backup*",
                f"{source_file.name}.backup*",
            ]
            
            backup_files = []
            for pattern in backup_patterns:
                backup_files.extend(source_file.parent.glob(pattern))
            
            if not backup_files:
                return
            
            # Lo·∫°i b·ªè file backup m·ªõi (ch∆∞a t·ªìn t·∫°i) kh·ªèi danh s√°ch
            existing_backups = [f for f in backup_files if f.exists() and f != new_backup]
            
            if len(existing_backups) <= 1:
                # Ch·ªâ c√≥ 1 ho·∫∑c 0 backup, kh√¥ng c·∫ßn x√≥a
                return
            
            # S·∫Øp x·∫øp theo th·ªùi gian modified (m·ªõi nh·∫•t tr∆∞·ªõc)
            existing_backups.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # Gi·ªØ l·∫°i file m·ªõi nh·∫•t, x√≥a c√°c file c≈©
            latest_backup = existing_backups[0]
            old_backups = existing_backups[1:]
            
            deleted_count = 0
            deleted_size = 0
            
            for old_backup in old_backups:
                try:
                    size = old_backup.stat().st_size
                    old_backup.unlink()
                    deleted_count += 1
                    deleted_size += size
                    logger.info(f"  üóëÔ∏è  Deleted old backup: {old_backup.name}")
                except Exception as e:
                    logger.warning(f"  ‚ö†Ô∏è  Could not delete {old_backup.name}: {e}")
            
            if deleted_count > 0:
                logger.info(f"  ‚úÖ Cleaned up {deleted_count} old backups ({deleted_size / 1024 / 1024:.2f} MB freed)")
                
        except Exception as e:
            logger.warning(f"Error during backup cleanup: {e}")
    
    def _log_backup(self, backup_info: Dict[str, Any]) -> None:
        """
        Ghi log backup v√†o file JSON.
        
        Args:
            backup_info: Th√¥ng tin backup
        """
        try:
            # Load existing logs
            logs = []
            if self.log_file.exists():
                try:
                    with open(self.log_file, 'r', encoding='utf-8') as f:
                        logs = json.load(f)
                except (json.JSONDecodeError, IOError):
                    logs = []
            
            # Append new log
            logs.append(backup_info)
            
            # Keep only last 1000 entries to prevent file from growing too large
            if len(logs) > 1000:
                logs = logs[-1000:]
            
            # Write back
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.warning(f"Could not write backup log: {e}")
    
    def get_backup_history(self, source_file: Optional[Path] = None, limit: int = 10) -> list:
        """
        L·∫•y l·ªãch s·ª≠ backup.
        
        Args:
            source_file: L·ªçc theo file g·ªëc (optional)
            limit: S·ªë l∆∞·ª£ng b·∫£n ghi tr·∫£ v·ªÅ
        
        Returns:
            Danh s√°ch c√°c backup g·∫ßn nh·∫•t
        """
        try:
            if not self.log_file.exists():
                return []
            
            with open(self.log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
            
            # Filter by source file if provided
            if source_file:
                source_str = str(source_file)
                logs = [log for log in logs if log.get('source_file') == source_str]
            
            # Sort by timestamp (newest first)
            logs.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
            
            return logs[:limit]
            
        except Exception as e:
            logger.warning(f"Could not read backup history: {e}")
            return []
    
    def list_backups(self, source_file: Path) -> list:
        """
        Li·ªát k√™ t·∫•t c·∫£ file backup c·ªßa m·ªôt file g·ªëc.
        
        Args:
            source_file: File g·ªëc
        
        Returns:
            Danh s√°ch c√°c file backup (s·∫Øp x·∫øp theo th·ªùi gian, m·ªõi nh·∫•t tr∆∞·ªõc)
        """
        try:
            source_file = Path(source_file)
            source_stem = source_file.stem
            source_ext = source_file.suffix
            
            backup_patterns = [
                f"{source_stem}_backup_*{source_ext}",
                f"{source_stem}.backup*",
                f"{source_file.name}.backup*",
            ]
            
            backup_files = []
            for pattern in backup_patterns:
                backup_files.extend(source_file.parent.glob(pattern))
            
            # Sort by modification time (newest first)
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            return backup_files
            
        except Exception as e:
            logger.warning(f"Error listing backups: {e}")
            return []


# Convenience function for quick backup
def create_backup(source_file: Path, 
                 backup_suffix: Optional[str] = None,
                 keep_latest_only: bool = True,
                 log_dir: Optional[Path] = None) -> Optional[Path]:
    """
    H√†m ti·ªán √≠ch ƒë·ªÉ t·∫°o backup nhanh.
    
    Args:
        source_file: File c·∫ßn backup
        backup_suffix: H·∫≠u t·ªë backup (m·∫∑c ƒë·ªãnh: timestamp)
        keep_latest_only: Ch·ªâ gi·ªØ backup m·ªõi nh·∫•t
        log_dir: Th∆∞ m·ª•c log (m·∫∑c ƒë·ªãnh: data_processor/logs/backup)
    
    Returns:
        ƒê∆∞·ªùng d·∫´n file backup ho·∫∑c None
    """
    backup_logger = BackupLogger(log_dir=log_dir)
    return backup_logger.create_backup(source_file, backup_suffix, keep_latest_only)

