# Sector Analysis Implementation Plan - FINAL
# K·∫ø Ho·∫°ch Tri·ªÉn Khai Ph√¢n T√≠ch Ng√†nh - B·∫¢N HO√ÄN CH·ªàNH

**Version:** 1.0.0
**Date:** 2025-12-14
**Status:** üéØ READY FOR IMPLEMENTATION
**Author:** Claude Code + User Review

---

## üìã M·ª•c L·ª•c / Table of Contents

1. [üéØ Executive Summary](#-executive-summary)
2. [üèóÔ∏è System Architecture](#Ô∏è-system-architecture)
3. [üìä Data Integration](#-data-integration)
4. [‚öôÔ∏è Configuration System](#Ô∏è-configuration-system)
5. [üîß Processor Layer](#-processor-layer)
6. [üìà Streamlit Dashboard](#-streamlit-dashboard)
7. [üßÆ Calculation Formulas](#-calculation-formulas)
8. [üìÅ File Structure](#-file-structure)
9. [üöÄ Implementation Roadmap](#-implementation-roadmap)
10. [‚úÖ Testing & Validation](#-testing--validation)

---

## üéØ Executive Summary

### M·ª•c Ti√™u / Objectives

X√¢y d·ª±ng h·ªá th·ªëng ph√¢n t√≠ch ng√†nh (Sector Analysis) t√≠ch h·ª£p **Fundamental Analysis (FA)** v√† **Technical/Valuation Analysis (TA)** cho 19 ng√†nh trong th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam.

### Y√™u C·∫ßu Ch√≠nh / Key Requirements

1. **FA Aggregation**: T·ªïng h·ª£p metrics t√†i ch√≠nh t·ª´ 457 tickers ‚Üí 19 sectors
2. **TA Aggregation**: T√≠nh to√°n ƒë·ªãnh gi√° ng√†nh (PE, PB, PS, EV/EBITDA)
3. **Configuration**: Qu·∫£n l√Ω weights v√† preferences cho FA/TA scoring
4. **Streamlit UI**: Dashboard t∆∞∆°ng t√°c v·ªõi charts, tables, filters
5. **System Integration**: Tu√¢n th·ªß v4.0.0 architecture (config/, DATA/, PROCESSORS/)

### Current System Status / T√¨nh Tr·∫°ng H·ªá Th·ªëng

| Component | Status | Location | Notes |
|-----------|--------|----------|-------|
| **‚úÖ Foundation Ready** |
| MetricRegistry | ‚úÖ Production | `config/metadata/metric_registry.json` | 2,099 metrics |
| SectorRegistry | ‚úÖ Production | `config/registries/sector_lookup.py` | 457 tickers √ó 19 sectors |
| SchemaRegistry | ‚úÖ Production | `config/schema_registry.py` | v4.0.0 compliant |
| Unit Standards | ‚úÖ Production | `config/unit_standards.json` | VND storage, decimal ratios |
| **‚úÖ Data Ready** |
| Company Metrics | ‚úÖ Production | `DATA/processed/fundamental/company/` | 386 tickers, 23 metrics |
| Bank Metrics | ‚úÖ Production | `DATA/processed/fundamental/bank/` | 24 tickers, 38 metrics |
| Security Metrics | ‚úÖ Production | `DATA/processed/fundamental/security/` | 37 tickers, 45 metrics |
| Valuation Data | ‚úÖ Production | `DATA/processed/valuation/pe/` | PE historical + latest |
| Technical Data | ‚úÖ Production | `DATA/processed/technical/` | OHLCV + indicators |
| **‚ö†Ô∏è Partial Implementation** |
| Sector FA Metrics | ‚ö†Ô∏è Partial | `DATA/processed/sector/sector_fundamental_metrics.parquet` | 558 rows, needs update |
| Sector Valuation | ‚ö†Ô∏è Partial | `DATA/processed/sector/sector_valuation_metrics.parquet` | 512K rows, wrong format |
| **‚ùå Missing Components** |
| FA Aggregator | ‚ùå Missing | `PROCESSORS/sector/calculators/fa_aggregator.py` | Need to create |
| TA Aggregator | ‚ùå Missing | `PROCESSORS/sector/calculators/ta_aggregator.py` | Need to create |
| Config Manager | ‚ùå Missing | `config/sector_analysis/config_manager.py` | Need to create |
| Sector Dashboard | ‚ö†Ô∏è Partial | `WEBAPP/pages/valuation_sector_dashboard.py` | Only PE, needs FA+TA |
| Sector Service | ‚ùå Missing | `WEBAPP/services/sector_service.py` | Need to create |

---

## üèóÔ∏è System Architecture

### High-Level Architecture / Ki·∫øn Tr√∫c T·ªïng Quan

```mermaid
graph TB
    subgraph "DATA Layer"
        D1[Company Metrics<br/>386 tickers]
        D2[Bank Metrics<br/>24 tickers]
        D3[Security Metrics<br/>37 tickers]
        D4[Insurance Metrics<br/>6 tickers]
        D5[Technical Data<br/>OHLCV + Indicators]
        D6[Valuation Data<br/>PE/PB/PS]
    end

    subgraph "CONFIG Layer"
        C1[MetricRegistry<br/>2,099 metrics]
        C2[SectorRegistry<br/>19 sectors]
        C3[SchemaRegistry<br/>v4.0.0]
        C4[ConfigManager<br/>FA/TA weights]
    end

    subgraph "PROCESSOR Layer"
        P1[FA Aggregator<br/>Sum-based]
        P2[TA Aggregator<br/>Market-cap weighted]
        P3[Sector Processor<br/>Orchestrator]
    end

    subgraph "OUTPUT"
        O1[sector_fundamental_metrics.parquet]
        O2[sector_valuation_metrics.parquet]
        O3[sector_combined_scores.parquet]
    end

    subgraph "STREAMLIT Layer"
        S1[Sector Service<br/>Data Access API]
        S2[Sector Dashboard<br/>FA+TA UI]
    end

    D1 --> P1
    D2 --> P1
    D3 --> P1
    D4 --> P1
    D5 --> P2
    D6 --> P2

    C1 --> P1
    C2 --> P1
    C2 --> P2
    C3 --> P1
    C4 --> P3

    P1 --> O1
    P2 --> O2
    P1 --> P3
    P2 --> P3
    P3 --> O3

    O1 --> S1
    O2 --> S1
    O3 --> S1
    S1 --> S2
```

### Data Flow / Lu·ªìng D·ªØ Li·ªáu

```
1. INPUT LAYER (DATA/processed/)
   ‚îú‚îÄ‚îÄ fundamental/company/*.parquet      ‚Üí FA Aggregator
   ‚îú‚îÄ‚îÄ fundamental/bank/*.parquet         ‚Üí FA Aggregator
   ‚îú‚îÄ‚îÄ fundamental/security/*.parquet     ‚Üí FA Aggregator
   ‚îú‚îÄ‚îÄ technical/basic_data.parquet       ‚Üí TA Aggregator
   ‚îî‚îÄ‚îÄ valuation/pe/*.parquet             ‚Üí TA Aggregator

2. PROCESSING LAYER (PROCESSORS/sector/)
   ‚îú‚îÄ‚îÄ FA Aggregator
   ‚îÇ   ‚îú‚îÄ‚îÄ Load metrics by entity type
   ‚îÇ   ‚îú‚îÄ‚îÄ Map tickers ‚Üí sectors (SectorRegistry)
   ‚îÇ   ‚îú‚îÄ‚îÄ Sum absolute values (revenue, profit, assets)
   ‚îÇ   ‚îú‚îÄ‚îÄ Calculate ratios (ROE, margins, growth)
   ‚îÇ   ‚îî‚îÄ‚îÄ Output: sector_fundamental_metrics.parquet
   ‚îÇ
   ‚îú‚îÄ‚îÄ TA Aggregator
   ‚îÇ   ‚îú‚îÄ‚îÄ Load market cap + valuation data
   ‚îÇ   ‚îú‚îÄ‚îÄ Calculate sector PE/PB/PS (market-cap weighted)
   ‚îÇ   ‚îú‚îÄ‚îÄ Calculate historical percentiles (5Y)
   ‚îÇ   ‚îú‚îÄ‚îÄ Calculate cross-sectional distribution
   ‚îÇ   ‚îî‚îÄ‚îÄ Output: sector_valuation_metrics.parquet
   ‚îÇ
   ‚îî‚îÄ‚îÄ Sector Processor (Orchestrator)
       ‚îú‚îÄ‚îÄ Load FA scores + TA scores
       ‚îú‚îÄ‚îÄ Apply weights from ConfigManager
       ‚îú‚îÄ‚îÄ Calculate combined score
       ‚îú‚îÄ‚îÄ Generate signals (Buy/Sell/Hold)
       ‚îî‚îÄ‚îÄ Output: sector_combined_scores.parquet

3. CONFIG LAYER (config/)
   ‚îú‚îÄ‚îÄ registries/
   ‚îÇ   ‚îú‚îÄ‚îÄ MetricRegistry      ‚Üí Metric code mapping
   ‚îÇ   ‚îî‚îÄ‚îÄ SectorRegistry      ‚Üí Ticker ‚Üí Sector mapping
   ‚îú‚îÄ‚îÄ schema_registry/        ‚Üí Data schemas
   ‚îî‚îÄ‚îÄ sector_analysis/
       ‚îî‚îÄ‚îÄ ConfigManager       ‚Üí FA/TA weights, thresholds

4. OUTPUT LAYER (DATA/processed/sector/)
   ‚îú‚îÄ‚îÄ sector_fundamental_metrics.parquet    ‚Üí FA results
   ‚îú‚îÄ‚îÄ sector_valuation_metrics.parquet      ‚Üí TA results
   ‚îî‚îÄ‚îÄ sector_combined_scores.parquet        ‚Üí FA+TA combined

5. STREAMLIT LAYER (WEBAPP/)
   ‚îú‚îÄ‚îÄ services/sector_service.py    ‚Üí Data access API
   ‚îî‚îÄ‚îÄ pages/sector_dashboard.py     ‚Üí UI + Charts
```

---

## üìä Data Integration

### 3.1 Input Data Sources / Ngu·ªìn D·ªØ Li·ªáu ƒê·∫ßu V√†o

#### A. Fundamental Data (FA)

**Location:** `DATA/processed/fundamental/`

| Entity Type | File | Tickers | Metrics | Key Columns |
|-------------|------|---------|---------|-------------|
| **Company** | `company/company_financial_metrics.parquet` | 386 | 23 | `symbol`, `report_date`, `total_revenue`, `net_profit`, `total_assets`, `total_equity`, `roe`, `gross_margin` |
| **Bank** | `bank/bank_financial_metrics.parquet` | 24 | 38 | `symbol`, `report_date`, `total_assets`, `customer_loans`, `customer_deposits`, `nii`, `nim_q`, `npl_ratio`, `roea_ttm` |
| **Security** | `security/security_financial_metrics.parquet` | 37 | 45 | `symbol`, `report_date`, `total_assets`, `margin_loans`, `fvtpl_assets`, `total_revenue`, `brokerage_revenue` |
| **Insurance** | `insurance/insurance_financial_metrics.parquet` | 6 | 30+ | `symbol`, `report_date`, `total_assets`, `total_equity`, `net_profit`, `roe` |

**Data Characteristics:**
- **Frequency:** Quarterly (report_date)
- **Unit Standards:** v4.0.0 compliant
  - Absolute values: VND (not billions)
  - Ratios: Decimal (0.15 not 15%)
- **Date Range:** 2018-Q1 to 2025-Q3
- **Missing Data:** Some early quarters may have nulls

#### B. Technical Data (TA)

**Location:** `DATA/processed/technical/basic_data.parquet`

| Column | Type | Description |
|--------|------|-------------|
| `symbol` | string | Ticker symbol |
| `date` | date | Trading date |
| `close` | float | Closing price (VND) |
| `volume` | int | Trading volume |
| `market_cap` | float | Market capitalization (VND) |
| `ma_20` | float | 20-day moving average |
| `ma_50` | float | 50-day moving average |
| `rsi` | float | RSI (0-100) |
| `macd` | float | MACD value |
| `atr` | float | Average True Range |

**Data Characteristics:**
- **Frequency:** Daily
- **Date Range:** 2015-01-05 to latest
- **Coverage:** All 457 tickers

#### C. Valuation Data (TA)

**Location:** `DATA/processed/valuation/`

**PE Ratio:**
- `pe/pe_historical.parquet` - Time series PE for all tickers
- `pe/pe_latest.parquet` - Latest PE snapshot

**PB Ratio:**
- `pb/pb_historical.parquet` - Time series PB
- `pb/pb_latest.parquet` - Latest PB

**Sector PE:**
- `sector_pe/sector_pe_historical.parquet` - Sector PE time series
- `sector_pe/sector_pe_latest.parquet` - Latest sector PE with percentiles

| Column | Type | Description |
|--------|------|-------------|
| `date` | date | Trading date |
| `sector` | string | Sector name (19 sectors) |
| `sector_pe` | float | Market-cap weighted PE |
| `pe_median` | float | Median PE of constituents |
| `pe_mean` | float | Average PE |
| `pe_std` | float | Standard deviation |
| `pe_q25` | float | 25th percentile |
| `pe_q75` | float | 75th percentile |
| `pe_min` | float | Minimum PE |
| `pe_max` | float | Maximum PE |
| `pe_percentile` | float | Current PE percentile (0-100) |
| `observation_days` | int | Number of days in calculation |

### 3.2 Output Data Schemas / C·∫•u Tr√∫c D·ªØ Li·ªáu ƒê·∫ßu Ra

#### A. sector_fundamental_metrics.parquet

**Purpose:** T·ªïng h·ª£p metrics t√†i ch√≠nh theo ng√†nh

**Schema:**

```python
{
    # Identifiers
    "sector_code": "string",           # Standardized sector name
    "sector_name_vi": "string",        # Vietnamese sector name
    "report_date": "date",             # Quarter end date (YYYY-MM-DD)
    "entity_types": "list[string]",    # Entity types in sector
    "ticker_count": "int",             # Number of tickers in sector

    # Absolute Metrics (VND - v4.0.0)
    "total_revenue": "float",          # Sum of revenue (VND)
    "net_profit": "float",             # Sum of net profit (VND)
    "total_assets": "float",           # Sum of total assets (VND)
    "total_equity": "float",           # Sum of total equity (VND)
    "total_liabilities": "float",      # Sum of total liabilities (VND)
    "gross_profit": "float",           # Sum of gross profit (VND)
    "operating_profit": "float",       # Sum of operating profit (VND)
    "selling_expenses": "float",       # Sum of selling expenses (VND)
    "general_admin_expenses": "float", # Sum of G&A expenses (VND)
    "ebit": "float",                   # Earnings Before Interest and Taxes
    "ebitda": "float",                 # Earnings Before Interest, Taxes, Depreciation, Amortization
    "total_debt": "float",             # Sum of total debt (VND)
    "accumulated_depreciation": "float", # Sum of accumulated depreciation
    "gross_fixed_assets": "float",     # Sum of gross fixed assets
    "construction_in_progress": "float", # Sum of CIP



    # Calculated Ratios (Decimal - v4.0.0)
    "gross_margin": "float",           # Gross Profit / Revenue
    "operating_margin": "float",       # Operating Profit / Revenue
    "net_margin": "float",             # Net Profit / Revenue
    "roe": "float",                    # Net Profit / Total Equity
    "roa": "float",                    # Net Profit / Total Assets
    "debt_to_equity": "float",         # Total Liabilities / Total Equity
    "sga_ratio": "float",              # (Selling + Admin) / Revenue


    # Growth Rates (Decimal - v4.0.0)
    "revenue_growth_yoy": "float",     # YoY revenue growth
    "profit_growth_yoy": "float",      # YoY profit growth
    "revenue_growth_qoq": "float",     # QoQ revenue growth
    "profit_growth_qoq": "float",      # QoQ profit growth

    # Bank-Specific (if applicable)
    "customer_loans": "float",         # Sum of loans (VND)
    "customer_deposits": "float",      # Sum of deposits (VND)
    "nii": "float",                    # Sum of net interest income (VND)
    "toi": "float",                    # Sum of total operating income
    "noii": "float",                   # Sum of non-interest income
    "opex": "float",                   # Sum of operating expenses
    "ppop": "float",                   # Sum of pre-provision operating profit
    "provision_expenses": "float",     # Sum of provision expenses
    "pbt": "float",                    # Sum of profit before tax
    "total_credit": "float",           # Sum of total credit (loans + bonds)
    "total_bad_debt": "float",         # Sum of bad debt (Group 3-5)
    "avg_total_assets": "float",       # Sum of average assets 
    "avg_total_equity": "float",       # Sum of average equity
    "interest_income": "float",        # Sum of interest income
    "interest_expenses": "float",      # Sum of interest expenses
    "net_interbank": "float",          # Sum of net interbank assets
    "liquid_reserves": "float",        # Sum of liquid reserves
    "casa_deposits": "float",          # Sum of CASA deposits

    "nim_q": "float",                  # Sector NIM (calculated)
    "npl_ratio": "float",              # Sector NPL ratio
    "ldr": "float",                    # Sector LDR
    "casa_ratio": "float",             # Sector CASA ratio
    "credit_cost": "float",            # Sector Credit Cost
    "cir": "float",                    # Sector CIR

    # Security-Specific (if applicable)
    "margin_loans": "float",           # Sum of margin loans (VND)
    "fvtpl_assets": "float",           # Sum of FVTPL assets (VND)
    "htm_assets": "float",             # Sum of HTM assets (VND)
    "available_for_sale_assets": "float", # Sum of AFS assets
    "total_investment": "float",       # Sum of total portion of investment (FVTPL+HTM+AFS)
    "brokerage_revenue": "float",      # Sum of brokerage revenue (VND)
    "fvtpl_income": "float",           # Sum of income from FVTPL
    "htm_income": "float",             # Sum of income from HTM
    "margin_income": "float",          # Sum of income from margin loans

    # Metadata
    "calculation_date": "timestamp",   # When calculated
    "data_quality_score": "float"      # 0-1 score (% non-null data)
}
```

**Example Row:**

```python
{
    "sector_code": "Banking",
    "sector_name_vi": "Ng√¢n h√†ng",
    "report_date": "2025-09-30",
    "entity_types": ["BANK"],
    "ticker_count": 24,

    "total_revenue": 4.5e14,           # 450 trillion VND
    "net_profit": 8.2e13,              # 82 trillion VND
    "total_assets": 1.8e16,            # 18,000 trillion VND
    "total_equity": 1.2e15,            # 1,200 trillion VND

    "gross_margin": None,              # N/A for banks
    "net_margin": 0.1822,              # 18.22%
    "roe": 0.0683,                     # 6.83%
    "roa": 0.0046,                     # 0.46%

    "customer_loans": 8.6e15,          # 8,600 trillion VND
    "customer_deposits": 4.8e15,       # 4,800 trillion VND
    "nii": 2.1e14,                     # 210 trillion VND
    "nim_q": 0.069,                    # 6.9% (annualized)
    "npl_ratio": 0.0185,               # 1.85%
    "ldr": 1.79,                       # 179%
    "casa_ratio": 0.285,               # 28.5%

    "calculation_date": "2025-12-14T10:30:00",
    "data_quality_score": 0.98
}
```

#### B. sector_valuation_metrics.parquet

**Purpose:** ƒê·ªãnh gi√° ng√†nh theo th·ªùi gian

**Schema:**

```python
{
    # Identifiers
    "sector_code": "string",           # Standardized sector name
    "date": "date",                    # Trading date

    # Market Metrics
    "sector_market_cap": "float",      # Sum of market caps (VND)
    "avg_price": "float",              # Average price (VND)
    "total_volume": "int",             # Sum of volume
    "total_trading_value": "float",    # Sum of trading value (Volume * Price)

    # Valuation Multiples (Market-cap weighted)
    "sector_pe": "float",              # Market Cap / TTM Earnings
    "sector_pb": "float",              # Market Cap / Book Value
    "sector_ps": "float",              # Market Cap / TTM Revenue
    "sector_ev_ebitda": "float",       # EV / EBITDA

    # Cross-Sectional Distribution (at date)
    "pe_median": "float",              # Median PE of constituents
    "pe_mean": "float",                # Average PE
    "pe_std": "float",                 # Standard deviation
    "pe_q25": "float",                 # 25th percentile
    "pe_q75": "float",                 # 75th percentile
    "pe_min": "float",                 # Minimum PE
    "pe_max": "float",                 # Maximum PE

    # Same for PB
    "pb_median": "float",
    "pb_mean": "float",
    "pb_std": "float",
    "pb_q25": "float",
    "pb_q75": "float",

    # Historical Percentile (5-year rolling)
    "pe_percentile_5y": "float",       # Current PE vs 5Y history (0-100)
    "pb_percentile_5y": "float",       # Current PB vs 5Y history
    "ps_percentile_5y": "float",       # Current PS vs 5Y history

    # Metadata
    "ticker_count": "int",             # Number of tickers used
    "calculation_date": "timestamp"    # When calculated
}
```

#### C. sector_combined_scores.parquet

**Purpose:** K·∫øt h·ª£p FA + TA scores v√† signals

**Schema:**

```python
{
    # Identifiers
    "sector_code": "string",
    "report_date": "date",             # Latest quarter
    "calculation_date": "timestamp",

    # FA Scores (0-100)
    "fa_growth_score": "float",        # Revenue/profit growth
    "fa_profitability_score": "float", # ROE, margins
    "fa_efficiency_score": "float",    # Asset turnover, etc.
    "fa_financial_health_score": "float", # Debt ratios
    "fa_total_score": "float",         # Weighted average

    # TA Scores (0-100)
    "ta_valuation_score": "float",     # PE/PB percentiles
    "ta_momentum_score": "float",      # Price/volume trends
    "ta_breadth_score": "float",       # % stocks above MA
    "ta_total_score": "float",         # Weighted average

    # Combined Score
    "combined_score": "float",         # FA_weight * FA + TA_weight * TA
    "fa_weight": "float",              # Weight used for FA
    "ta_weight": "float",              # Weight used for TA

    # Signal
    "signal": "string",                # "BUY", "HOLD", "SELL"
    "signal_strength": "int",          # 1-5 (weak to strong)
    "signal_reason": "string",         # Human-readable explanation

    # Rankings
    "rank_fa": "int",                  # Rank by FA score (1-19)
    "rank_ta": "int",                  # Rank by TA score
    "rank_combined": "int",            # Rank by combined score

    # Metadata
    "config_version": "string"         # Config version used
}
```

---

## ‚öôÔ∏è Configuration System

### 4.1 Directory Structure / C·∫•u Tr√∫c Th∆∞ M·ª•c

```
config/
‚îî‚îÄ‚îÄ sector_analysis/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ config_manager.py              # Main config manager class
    ‚îú‚îÄ‚îÄ default_config.json            # Default FA/TA weights
    ‚îú‚îÄ‚îÄ sector_specific_config.json    # Sector-specific overrides
    ‚îî‚îÄ‚îÄ scoring_thresholds.json        # Score calculation thresholds
```

### 4.2 ConfigManager Class

**File:** `config/sector_analysis/config_manager.py`

**Purpose:** Qu·∫£n l√Ω FA/TA weights, thresholds, v√† preferences

```python
#!/usr/bin/env python3
"""
Sector Analysis Configuration Manager
======================================

Manages FA/TA weights, scoring thresholds, and sector-specific configurations.

Usage:
    from config.sector_analysis import ConfigManager

    config = ConfigManager()
    weights = config.get_fa_ta_weights()
    fa_config = config.get_fa_config()

Author: Claude Code
Date: 2025-12-14
"""

from pathlib import Path
import json
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class ConfigManager:
    """
    Qu·∫£n l√Ω c·∫•u h√¨nh cho Sector Analysis
    Manages configuration for Sector Analysis
    """

    _instance = None
    _loaded = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ConfigManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not ConfigManager._loaded:
            self.config_dir = Path(__file__).parent
            self._load_configs()
            ConfigManager._loaded = True

    def _load_configs(self):
        """Load all configuration files"""
        # Default config
        default_path = self.config_dir / "default_config.json"
        if default_path.exists():
            with open(default_path, 'r', encoding='utf-8') as f:
                self.default_config = json.load(f)
        else:
            logger.warning("default_config.json not found, using hardcoded defaults")
            self.default_config = self._get_hardcoded_defaults()

        # Sector-specific config
        sector_path = self.config_dir / "sector_specific_config.json"
        if sector_path.exists():
            with open(sector_path, 'r', encoding='utf-8') as f:
                self.sector_config = json.load(f)
        else:
            self.sector_config = {}

        # Scoring thresholds
        threshold_path = self.config_dir / "scoring_thresholds.json"
        if threshold_path.exists():
            with open(threshold_path, 'r', encoding='utf-8') as f:
                self.thresholds = json.load(f)
        else:
            self.thresholds = self._get_default_thresholds()

        logger.info("ConfigManager initialized successfully")

    def _get_hardcoded_defaults(self) -> Dict[str, Any]:
        """Hardcoded default configuration"""
        return {
            "version": "1.0.0",
            "fa_ta_weights": {
                "fa_weight": 0.6,
                "ta_weight": 0.4
            },
            "fa_component_weights": {
                "growth": 0.3,
                "profitability": 0.4,
                "efficiency": 0.2,
                "financial_health": 0.1
            },
            "ta_component_weights": {
                "valuation": 0.5,
                "momentum": 0.3,
                "breadth": 0.2
            },
            "signal_thresholds": {
                "buy": 70,
                "sell": 30
            }
        }

    def _get_default_thresholds(self) -> Dict[str, Any]:
        """Default scoring thresholds"""
        return {
            "growth": {
                "excellent": 0.20,      # >20% YoY growth
                "good": 0.10,           # >10%
                "neutral": 0.05,        # >5%
                "poor": 0.00            # >0%
            },
            "profitability": {
                "roe_excellent": 0.20,
                "roe_good": 0.15,
                "roe_neutral": 0.10,
                "net_margin_excellent": 0.15,
                "net_margin_good": 0.10
            },
            "valuation": {
                "pe_cheap": 25,         # <25th percentile
                "pe_expensive": 75      # >75th percentile
            }
        }

    def get_fa_ta_weights(self, sector: Optional[str] = None) -> Dict[str, float]:
        """
        Get FA/TA weights for a sector

        Args:
            sector: Sector code (optional, uses default if None)

        Returns:
            {"fa_weight": 0.6, "ta_weight": 0.4}
        """
        if sector and sector in self.sector_config:
            weights = self.sector_config[sector].get("fa_ta_weights")
            if weights:
                return weights

        return self.default_config["fa_ta_weights"]

    def get_fa_config(self, sector: Optional[str] = None) -> Dict[str, Any]:
        """Get FA configuration"""
        config = {
            "component_weights": self.default_config["fa_component_weights"],
            "thresholds": self.thresholds
        }

        # Sector-specific overrides
        if sector and sector in self.sector_config:
            sector_fa = self.sector_config[sector].get("fa_config", {})
            config.update(sector_fa)

        return config

    def get_ta_config(self, sector: Optional[str] = None) -> Dict[str, Any]:
        """Get TA configuration"""
        config = {
            "component_weights": self.default_config["ta_component_weights"],
            "thresholds": self.thresholds.get("valuation", {})
        }

        # Sector-specific overrides
        if sector and sector in self.sector_config:
            sector_ta = self.sector_config[sector].get("ta_config", {})
            config.update(sector_ta)

        return config

    def get_signal_thresholds(self) -> Dict[str, float]:
        """Get signal generation thresholds"""
        return self.default_config["signal_thresholds"]

    def get_sector_specific_config(self, sector: str) -> Dict[str, Any]:
        """Get complete config for a specific sector"""
        return self.sector_config.get(sector, {})


# Convenience function
_config_manager = None

def get_config_manager() -> ConfigManager:
    """Get singleton ConfigManager instance"""
    global _config_manager
    if _config_manager is None:
        _config_manager = ConfigManager()
    return _config_manager
```

### 4.3 Configuration Files

#### A. default_config.json

**File:** `config/sector_analysis/default_config.json`

```json
{
  "version": "1.0.0",
  "description": "Default configuration for sector analysis",

  "fa_ta_weights": {
    "fa_weight": 0.6,
    "ta_weight": 0.4,
    "description": "Default 60/40 split (FA/TA)"
  },

  "fa_component_weights": {
    "growth": 0.3,
    "profitability": 0.4,
    "efficiency": 0.2,
    "financial_health": 0.1,
    "description": "Weights for FA sub-scores"
  },

  "ta_component_weights": {
    "valuation": 0.5,
    "momentum": 0.3,
    "breadth": 0.2,
    "description": "Weights for TA sub-scores"
  },

  "signal_thresholds": {
    "buy": 70,
    "sell": 30,
    "description": "Combined score thresholds for signals"
  },

  "lookback_periods": {
    "growth_calculation": "1Y",
    "valuation_percentile": "5Y",
    "momentum_calculation": "20D",
    "description": "Time periods for calculations"
  }
}
```

#### B. sector_specific_config.json

**File:** `config/sector_analysis/sector_specific_config.json`

```json
{
  "Banking": {
    "description": "Bank sector uses different FA/TA weights",
    "fa_ta_weights": {
      "fa_weight": 0.7,
      "ta_weight": 0.3,
      "reason": "Fundamentals more important for banks"
    },
    "fa_config": {
      "component_weights": {
        "growth": 0.25,
        "profitability": 0.35,
        "efficiency": 0.15,
        "financial_health": 0.25,
        "asset_quality": 0.0
      },
      "key_metrics": ["nim_q", "roea_ttm", "npl_ratio", "casa_ratio"]
    }
  },

  "Technology": {
    "description": "Tech sector emphasizes growth",
    "fa_ta_weights": {
      "fa_weight": 0.5,
      "ta_weight": 0.5
    },
    "fa_config": {
      "component_weights": {
        "growth": 0.5,
        "profitability": 0.3,
        "efficiency": 0.1,
        "financial_health": 0.1
      }
    }
  },

  "Real Estate": {
    "description": "Real estate sensitive to valuation",
    "ta_config": {
      "component_weights": {
        "valuation": 0.6,
        "momentum": 0.2,
        "breadth": 0.2
      }
    }
  }
}
```

#### C. scoring_thresholds.json

**File:** `config/sector_analysis/scoring_thresholds.json`

```json
{
  "growth": {
    "revenue_yoy": {
      "excellent": 0.20,
      "good": 0.10,
      "neutral": 0.05,
      "poor": 0.00,
      "terrible": -0.05
    },
    "profit_yoy": {
      "excellent": 0.25,
      "good": 0.15,
      "neutral": 0.05,
      "poor": 0.00,
      "terrible": -0.10
    }
  },

  "profitability": {
    "roe": {
      "excellent": 0.20,
      "good": 0.15,
      "neutral": 0.10,
      "poor": 0.05,
      "terrible": 0.00
    },
    "net_margin": {
      "excellent": 0.15,
      "good": 0.10,
      "neutral": 0.05,
      "poor": 0.02,
      "terrible": 0.00
    },
    "roa": {
      "excellent": 0.10,
      "good": 0.07,
      "neutral": 0.05,
      "poor": 0.02
    }
  },

  "efficiency": {
    "asset_turnover": {
      "excellent": 1.5,
      "good": 1.0,
      "neutral": 0.7,
      "poor": 0.5
    }
  },

  "financial_health": {
    "debt_to_equity": {
      "excellent": 0.5,
      "good": 1.0,
      "neutral": 1.5,
      "poor": 2.0,
      "terrible": 3.0
    }
  },

  "valuation": {
    "pe_percentile": {
      "very_cheap": 10,
      "cheap": 25,
      "fair": 50,
      "expensive": 75,
      "very_expensive": 90
    },
    "pb_percentile": {
      "very_cheap": 10,
      "cheap": 25,
      "fair": 50,
      "expensive": 75,
      "very_expensive": 90
    }
  },

  "momentum": {
    "price_change_20d": {
      "strong_up": 0.10,
      "up": 0.05,
      "neutral": 0.00,
      "down": -0.05,
      "strong_down": -0.10
    }
  }
}
```

---

## üîß Processor Layer

### 5.1 Directory Structure

```
PROCESSORS/
‚îî‚îÄ‚îÄ sector/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ calculators/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fa_aggregator.py           # FA metrics aggregation
    ‚îÇ   ‚îú‚îÄ‚îÄ ta_aggregator.py           # TA metrics aggregation
    ‚îÇ   ‚îî‚îÄ‚îÄ base_aggregator.py         # Shared utilities
    ‚îú‚îÄ‚îÄ scoring/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ fa_scorer.py               # FA scoring logic
    ‚îÇ   ‚îú‚îÄ‚îÄ ta_scorer.py               # TA scoring logic
    ‚îÇ   ‚îî‚îÄ‚îÄ signal_generator.py        # Signal generation
    ‚îú‚îÄ‚îÄ sector_processor.py            # Main orchestrator
    ‚îî‚îÄ‚îÄ run_sector_analysis.py         # CLI runner
```

### 5.2 FA Aggregator

**File:** `PROCESSORS/sector/calculators/fa_aggregator.py`

**Purpose:** T·ªïng h·ª£p fundamental metrics theo ng√†nh

**Key Functions:**

1. **Load and Map Data**
   - Load company/bank/security/insurance metrics
   - Map tickers to sectors using SectorRegistry
   - Filter by date range

2. **Aggregate Absolute Metrics**
    - Sum: revenue, profit, assets, equity, liabilities, gross_profit, operating_profit, selling_expenses, general_admin_expenses
   - Bank-specific: loans, deposits, NII

   - Security-specific: margin loans, FVTPL

3. **Calculate Ratios**
   - From aggregated sums: ROE, margins, LDR, NIM
   - Sector-level ratios (not averages!)

4. **Calculate Growth**
   - YoY, QoQ growth from aggregated data

**Pseudocode:**

```python
class FAggregator:
    def __init__(self, config_manager, sector_registry, metric_registry):
        self.config = config_manager
        self.sector_reg = sector_registry
        self.metric_reg = metric_registry

    def aggregate_sector_fundamentals(self, report_date=None):
        """
        Main aggregation function

        Returns:
            DataFrame with schema matching sector_fundamental_metrics
        """
        # 1. Load all entity data
        company_df = self._load_company_data()
        bank_df = self._load_bank_data()
        security_df = self._load_security_data()
        insurance_df = self._load_insurance_data()

        # 2. Map tickers to sectors
        company_df = self._add_sector_mapping(company_df)
        bank_df = self._add_sector_mapping(bank_df)
        security_df = self._add_sector_mapping(security_df)
        insurance_df = self._add_sector_mapping(insurance_df)

        # 3. Aggregate by sector
        results = []
        for sector in self.sector_reg.get_all_sectors():
            sector_data = self._aggregate_sector(
                sector, company_df, bank_df, security_df, insurance_df
            )
            results.append(sector_data)

        # 4. Combine and format
        sector_df = pd.DataFrame(results)
        sector_df = self._calculate_ratios(sector_df)
        sector_df = self._calculate_growth(sector_df)

        return sector_df

    def _aggregate_sector(self, sector, company_df, bank_df, security_df, insurance_df):
        """
        Aggregate one sector

        Logic:
        - Filter DataFrames for tickers in this sector
        - Sum all absolute metrics
        - Return dict with aggregated values
        """
        # Get tickers in sector
        tickers = self.sector_reg.get_tickers_by_sector(sector)

        # Filter dataframes
        sector_company = company_df[company_df['symbol'].isin(tickers)]
        sector_bank = bank_df[bank_df['symbol'].isin(tickers)]
        sector_security = security_df[security_df['symbol'].isin(tickers)]
        sector_insurance = insurance_df[insurance_df['symbol'].isin(tickers)]

        # Aggregate
        return {
            "sector_code": sector,
            "total_revenue": (
                sector_company['total_revenue'].sum() +
                sector_bank['total_revenue'].sum() +
                sector_security['total_revenue'].sum() +
                sector_insurance['total_revenue'].sum()
            ),
            # ... similar for all metrics
        }

    def _calculate_ratios(self, df):
        """
        Calculate ratios from aggregated sums

        Example:
            sector_roe = net_profit / total_equity
            sector_net_margin = net_profit / total_revenue
        """
        df['roe'] = df['net_profit'] / df['total_equity']
        df['net_margin'] = df['net_profit'] / df['total_revenue']
        df['roa'] = df['net_profit'] / df['total_assets']

        # Bank-specific
        if 'nii' in df.columns:
            df['nim_q'] = df['nii'] / df['interest_earning_assets']

        return df

    def _calculate_growth(self, df):
        """
        Calculate YoY and QoQ growth

        Logic:
        - Sort by sector + report_date
        - Use .shift() to get previous periods
        - Calculate growth rates
        """
        df = df.sort_values(['sector_code', 'report_date'])

        # YoY growth (4 quarters ago)
        df['revenue_growth_yoy'] = (
            df.groupby('sector_code')['total_revenue']
            .pct_change(periods=4)
        )

        # QoQ growth (1 quarter ago)
        df['revenue_growth_qoq'] = (
            df.groupby('sector_code')['total_revenue']
            .pct_change(periods=1)
        )

        return df
```

### 5.3 TA Aggregator

**File:** `PROCESSORS/sector/calculators/ta_aggregator.py`

**Purpose:** T√≠nh to√°n ƒë·ªãnh gi√° ng√†nh (market-cap weighted)

**Key Functions:**

1. **Load Market Data**
   - OHLCV data (price, volume, market cap)
   - Existing PE/PB data from valuation calculators

2. **Calculate Sector Valuation**
   - Sector PE = Œ£ Market Cap / Œ£ TTM Earnings
   - Sector PB = Œ£ Market Cap / Œ£ Book Value
   - Sector PS = Œ£ Market Cap / Œ£ TTM Revenue

3. **Calculate Cross-Sectional Distribution**
   - At each date: min, max, median, quartiles of constituent PEs

4. **Calculate Historical Percentiles**
   - 5-year rolling: where does current PE sit in history?

**Pseudocode:**

```python
class TAAggregator:
    def __init__(self, config_manager, sector_registry):
        self.config = config_manager
        self.sector_reg = sector_registry

    def aggregate_sector_valuation(self, start_date=None, end_date=None):
        """
        Main TA aggregation

        Returns:
            DataFrame with sector_valuation_metrics schema
        """
        # 1. Load data
        market_df = self._load_market_data()
        pe_df = self._load_pe_data()
        pb_df = self._load_pb_data()
        fundamental_df = self._load_fundamental_summary()

        # 2. Merge
        merged = market_df.merge(pe_df, on=['symbol', 'date'], how='left')
        merged = merged.merge(pb_df, on=['symbol', 'date'], how='left')
        merged = merged.merge(fundamental_df, on=['symbol'], how='left')

        # 3. Add sector mapping
        merged = self._add_sector_mapping(merged)

        # 4. Calculate sector metrics by date
        results = []
        for date in merged['date'].unique():
            date_df = merged[merged['date'] == date]
            for sector in date_df['sector_code'].unique():
                sector_metrics = self._calculate_sector_valuation_at_date(
                    sector, date, date_df
                )
                results.append(sector_metrics)

        sector_val_df = pd.DataFrame(results)

        # 5. Calculate historical percentiles
        sector_val_df = self._calculate_percentiles(sector_val_df)

        return sector_val_df

    def _calculate_sector_valuation_at_date(self, sector, date, df):
        """
        Calculate sector PE/PB/PS for one date

        Formula:
            Sector PE = Œ£(Market Cap) / Œ£(TTM Earnings)
        """
        sector_df = df[df['sector_code'] == sector]

        # Filter valid data (positive earnings, non-null PE)
        valid_df = sector_df[
            (sector_df['market_cap'] > 0) &
            (sector_df['ttm_earnings'] > 0)
        ]

        total_mcap = valid_df['market_cap'].sum()
        total_earnings = valid_df['ttm_earnings'].sum()
        total_book_value = valid_df['book_value'].sum()
        total_revenue = valid_df['ttm_revenue'].sum()

        # Sector multiples
        sector_pe = total_mcap / total_earnings if total_earnings > 0 else None
        sector_pb = total_mcap / total_book_value if total_book_value > 0 else None
        sector_ps = total_mcap / total_revenue if total_revenue > 0 else None

        # Cross-sectional distribution
        pe_stats = valid_df['pe'].describe()

        return {
            "sector_code": sector,
            "date": date,
            "sector_market_cap": total_mcap,
            "sector_pe": sector_pe,
            "sector_pb": sector_pb,
            "sector_ps": sector_ps,
            "pe_median": valid_df['pe'].median(),
            "pe_mean": valid_df['pe'].mean(),
            "pe_std": valid_df['pe'].std(),
            "pe_q25": valid_df['pe'].quantile(0.25),
            "pe_q75": valid_df['pe'].quantile(0.75),
            "pe_min": valid_df['pe'].min(),
            "pe_max": valid_df['pe'].max(),
            "ticker_count": len(valid_df)
        }

    def _calculate_percentiles(self, df):
        """
        Calculate where current value sits in 5Y history

        Logic:
        - For each sector + date, look back 5 years
        - Calculate percentile rank of current PE
        """
        df = df.sort_values(['sector_code', 'date'])

        def calc_percentile(group):
            # Rolling 5Y window
            window = group.tail(1260)  # ~5 years daily data
            current_pe = group.iloc[-1]['sector_pe']
            if pd.isna(current_pe):
                return None

            # Percentile rank
            return (window['sector_pe'] < current_pe).sum() / len(window) * 100

        df['pe_percentile_5y'] = (
            df.groupby('sector_code')
            .apply(calc_percentile)
            .reset_index(level=0, drop=True)
        )

        return df
```

### 5.4 Sector Processor (Orchestrator)

**File:** `PROCESSORS/sector/sector_processor.py`

**Purpose:** Orchestrate FA + TA aggregation and scoring

```python
#!/usr/bin/env python3
"""
Sector Processor - Main Orchestrator
=====================================

Orchestrates FA aggregation, TA aggregation, scoring, and signal generation.

Usage:
    from PROCESSORS.sector import SectorProcessor

    processor = SectorProcessor()
    processor.run_full_pipeline()

Author: Claude Code
Date: 2025-12-14
"""

from pathlib import Path
import pandas as pd
import logging
from datetime import datetime

from config.registries import MetricRegistry, SectorRegistry
from config.sector_analysis import ConfigManager
from PROCESSORS.sector.calculators import FAAggregator, TAAggregator
from PROCESSORS.sector.scoring import FAScorer, TAScorer, SignalGenerator

logger = logging.getLogger(__name__)


class SectorProcessor:
    """
    Main orchestrator for sector analysis pipeline
    """

    def __init__(self, output_dir: str = "DATA/processed/sector"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Initialize registries
        self.metric_reg = MetricRegistry()
        self.sector_reg = SectorRegistry()
        self.config = ConfigManager()

        # Initialize aggregators
        self.fa_agg = FAAggregator(self.config, self.sector_reg, self.metric_reg)
        self.ta_agg = TAAggregator(self.config, self.sector_reg)

        # Initialize scorers
        self.fa_scorer = FAScorer(self.config)
        self.ta_scorer = TAScorer(self.config)
        self.signal_gen = SignalGenerator(self.config)

    def run_full_pipeline(self, report_date=None):
        """
        Run complete sector analysis pipeline

        Steps:
        1. Aggregate FA metrics
        2. Aggregate TA metrics
        3. Calculate FA scores
        4. Calculate TA scores
        5. Combine scores
        6. Generate signals
        7. Save outputs
        """
        logger.info("=" * 80)
        logger.info("STARTING SECTOR ANALYSIS PIPELINE")
        logger.info("=" * 80)

        # Step 1: FA Aggregation
        logger.info("\n[1/7] Aggregating FA metrics...")
        fa_df = self.fa_agg.aggregate_sector_fundamentals(report_date)
        logger.info(f"  ‚Üí Generated {len(fa_df)} sector-quarter records")

        # Save FA output
        fa_output = self.output_dir / "sector_fundamental_metrics.parquet"
        fa_df.to_parquet(fa_output, index=False)
        logger.info(f"  ‚úÖ Saved to {fa_output}")

        # Step 2: TA Aggregation
        logger.info("\n[2/7] Aggregating TA metrics...")
        ta_df = self.ta_agg.aggregate_sector_valuation()
        logger.info(f"  ‚Üí Generated {len(ta_df)} sector-date records")

        # Save TA output
        ta_output = self.output_dir / "sector_valuation_metrics.parquet"
        ta_df.to_parquet(ta_output, index=False)
        logger.info(f"  ‚úÖ Saved to {ta_output}")

        # Step 3: Calculate FA Scores
        logger.info("\n[3/7] Calculating FA scores...")
        fa_scores = self.fa_scorer.calculate_scores(fa_df)
        logger.info(f"  ‚Üí Calculated scores for {len(fa_scores)} sectors")

        # Step 4: Calculate TA Scores
        logger.info("\n[4/7] Calculating TA scores...")
        ta_scores = self.ta_scorer.calculate_scores(ta_df)
        logger.info(f"  ‚Üí Calculated scores for {len(ta_scores)} sectors")

        # Step 5: Combine Scores
        logger.info("\n[5/7] Combining FA + TA scores...")
        combined = self._combine_scores(fa_scores, ta_scores)
        logger.info(f"  ‚Üí Combined {len(combined)} sector records")

        # Step 6: Generate Signals
        logger.info("\n[6/7] Generating signals...")
        with_signals = self.signal_gen.generate_signals(combined)
        logger.info(f"  ‚Üí Generated signals for {len(with_signals)} sectors")

        # Step 7: Save Combined Output
        logger.info("\n[7/7] Saving combined results...")
        combined_output = self.output_dir / "sector_combined_scores.parquet"
        with_signals.to_parquet(combined_output, index=False)
        logger.info(f"  ‚úÖ Saved to {combined_output}")

        # Summary
        logger.info("\n" + "=" * 80)
        logger.info("PIPELINE COMPLETED SUCCESSFULLY")
        logger.info("=" * 80)
        logger.info(f"  FA Metrics:      {fa_output}")
        logger.info(f"  TA Metrics:      {ta_output}")
        logger.info(f"  Combined Scores: {combined_output}")
        logger.info("=" * 80)

        return {
            "fa_df": fa_df,
            "ta_df": ta_df,
            "combined_df": with_signals
        }

    def _combine_scores(self, fa_scores, ta_scores):
        """
        Combine FA and TA scores

        Logic:
        - Merge on sector_code
        - Apply weights from ConfigManager
        - Calculate combined score
        """
        # Merge
        combined = fa_scores.merge(
            ta_scores,
            on='sector_code',
            how='outer',
            suffixes=('_fa', '_ta')
        )

        # Get weights for each sector
        combined['fa_weight'] = combined['sector_code'].apply(
            lambda s: self.config.get_fa_ta_weights(s)['fa_weight']
        )
        combined['ta_weight'] = combined['sector_code'].apply(
            lambda s: self.config.get_fa_ta_weights(s)['ta_weight']
        )

        # Calculate combined score
        combined['combined_score'] = (
            combined['fa_total_score'] * combined['fa_weight'] +
            combined['ta_total_score'] * combined['ta_weight']
        )

        # Calculate rankings
        combined['rank_fa'] = combined['fa_total_score'].rank(ascending=False)
        combined['rank_ta'] = combined['ta_total_score'].rank(ascending=False)
        combined['rank_combined'] = combined['combined_score'].rank(ascending=False)

        return combined


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    processor = SectorProcessor()
    processor.run_full_pipeline()
```

---

## üìà Streamlit Dashboard

### 6.1 Sector Service

**File:** `WEBAPP/services/sector_service.py`

**Purpose:** Single API cho sector data access

```python
#!/usr/bin/env python3
"""
Sector Service - Data Access Layer for Streamlit
=================================================

Provides unified API for accessing sector analysis data.

Usage:
    from WEBAPP.services.sector_service import SectorService

    service = SectorService()
    fa_data = service.get_fa_metrics(sector="Banking")
    ta_data = service.get_ta_metrics(sector="Banking")

Author: Claude Code
Date: 2025-12-14
"""

import pandas as pd
from pathlib import Path
from typing import Optional, List, Dict, Any
import streamlit as st
from datetime import datetime, timedelta

from config.registries import SectorRegistry
from config.schema_registry import SchemaRegistry


class SectorService:
    """
    Service layer for sector data access
    """

    def __init__(self, data_dir: str = "DATA/processed/sector"):
        self.data_dir = Path(data_dir)
        self.sector_reg = SectorRegistry()
        self.schema_reg = SchemaRegistry()

    @st.cache_data(ttl=3600)
    def get_fa_metrics(_self,
                       sector: Optional[str] = None,
                       start_date: Optional[str] = None,
                       end_date: Optional[str] = None) -> pd.DataFrame:
        """
        Get FA metrics for sectors

        Args:
            sector: Sector code (optional, returns all if None)
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)

        Returns:
            DataFrame with FA metrics
        """
        fa_path = _self.data_dir / "sector_fundamental_metrics.parquet"
        df = pd.read_parquet(fa_path)

        # Filter by sector
        if sector:
            df = df[df['sector_code'] == sector]

        # Filter by date
        if start_date:
            df = df[df['report_date'] >= start_date]
        if end_date:
            df = df[df['report_date'] <= end_date]

        return df

    @st.cache_data(ttl=3600)
    def get_ta_metrics(_self,
                       sector: Optional[str] = None,
                       start_date: Optional[str] = None,
                       end_date: Optional[str] = None) -> pd.DataFrame:
        """Get TA metrics for sectors"""
        ta_path = _self.data_dir / "sector_valuation_metrics.parquet"
        df = pd.read_parquet(ta_path)

        if sector:
            df = df[df['sector_code'] == sector]

        if start_date:
            df = df[df['date'] >= start_date]
        if end_date:
            df = df[df['date'] <= end_date]

        return df

    @st.cache_data(ttl=3600)
    def get_combined_scores(_self,
                            sector: Optional[str] = None) -> pd.DataFrame:
        """Get combined FA+TA scores"""
        combined_path = _self.data_dir / "sector_combined_scores.parquet"
        df = pd.read_parquet(combined_path)

        if sector:
            df = df[df['sector_code'] == sector]

        return df

    def get_all_sectors(_self) -> List[str]:
        """Get list of all sectors"""
        return _self.sector_reg.get_all_sectors()

    def get_sector_info(_self, sector: str) -> Dict[str, Any]:
        """Get sector metadata"""
        return {
            "sector_code": sector,
            "tickers": _self.sector_reg.get_tickers_by_sector(sector),
            "ticker_count": len(_self.sector_reg.get_tickers_by_sector(sector)),
            "entity_types": _self.sector_reg.get_entity_types_in_sector(sector)
        }

    def get_latest_fa_snapshot(_self) -> pd.DataFrame:
        """Get latest quarter FA data for all sectors"""
        df = _self.get_fa_metrics()
        latest_date = df['report_date'].max()
        return df[df['report_date'] == latest_date]

    def get_latest_ta_snapshot(_self) -> pd.DataFrame:
        """Get latest date TA data for all sectors"""
        df = _self.get_ta_metrics()
        latest_date = df['date'].max()
        return df[df['date'] == latest_date]

    def format_value(_self, value: float, format_type: str) -> str:
        """
        Format value using SchemaRegistry

        Args:
            value: Value to format
            format_type: 'price', 'percentage', 'ratio', 'market_cap'

        Returns:
            Formatted string
        """
        if format_type == 'price':
            return _self.schema_reg.format_price(value)
        elif format_type == 'percentage':
            return _self.schema_reg.format_percentage(value)
        elif format_type == 'ratio':
            return _self.schema_reg.format_ratio(value)
        elif format_type == 'market_cap':
            return _self.schema_reg.format_market_cap(value)
        else:
            return str(value)
```

### 6.2 Sector Dashboard

**File:** `WEBAPP/pages/sector_analysis_dashboard.py`

**Purpose:** Unified FA+TA sector analysis UI

**Key Features:**

1. **Sidebar Filters**
   - Sector selection (multi-select)
   - Date range picker
   - FA/TA weight adjustment slider

2. **Main Content**
   - **Tab 1: Overview**
     - Sector comparison table (latest scores)
     - Combined score chart (bar chart)
   - **Tab 2: Fundamental Analysis**
     - FA metrics table
     - Growth charts (revenue, profit)
     - Profitability charts (ROE, margins)
   - **Tab 3: Valuation Analysis**
     - Historical PE/PB charts
     - "Candlestick" distribution chart (P25-P75 range)
     - Cross-sectional boxplot
   - **Tab 4: Signals**
     - Buy/Sell/Hold signals table
     - Signal strength heatmap

**Pseudocode:**

```python
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px

from WEBAPP.services.sector_service import SectorService
from config.schema_registry import SchemaRegistry

# Initialize
service = SectorService()
schema_reg = SchemaRegistry()

# Page config
st.set_page_config(page_title="Sector Analysis", layout="wide")

# Sidebar
with st.sidebar:
    st.title("Filters")

    # Sector selection
    all_sectors = service.get_all_sectors()
    selected_sectors = st.multiselect("Sectors", all_sectors, default=all_sectors[:5])

    # Date range
    date_range = st.date_input("Date Range", value=(
        datetime.now() - timedelta(days=365),
        datetime.now()
    ))

    # FA/TA weights (optional override)
    st.subheader("Weights")
    fa_weight = st.slider("FA Weight", 0.0, 1.0, 0.6, 0.1)
    ta_weight = 1.0 - fa_weight
    st.info(f"TA Weight: {ta_weight:.1f}")

# Main content
st.title("üè¢ Sector Analysis Dashboard")
st.markdown("Ph√¢n t√≠ch ng√†nh t√≠ch h·ª£p FA + TA")

# Tabs
tab1, tab2, tab3, tab4 = st.tabs([
    "Overview", "Fundamental", "Valuation", "Signals"
])

with tab1:
    st.header("Sector Overview")

    # Latest scores
    combined_df = service.get_combined_scores()
    if selected_sectors:
        combined_df = combined_df[combined_df['sector_code'].isin(selected_sectors)]

    # Table
    st.subheader("Sector Scores")
    display_df = combined_df[[
        'sector_code', 'fa_total_score', 'ta_total_score',
        'combined_score', 'signal', 'signal_strength'
    ]].sort_values('combined_score', ascending=False)

    st.dataframe(display_df, use_container_width=True)

    # Chart
    fig = px.bar(
        display_df,
        x='sector_code',
        y='combined_score',
        color='signal',
        title="Combined Score by Sector"
    )
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("Fundamental Analysis")

    # Load FA data
    fa_df = service.get_fa_metrics(
        start_date=str(date_range[0]),
        end_date=str(date_range[1])
    )

    if selected_sectors:
        fa_df = fa_df[fa_df['sector_code'].isin(selected_sectors)]

    # Metrics selection
    metric = st.selectbox("Select Metric", [
        'total_revenue', 'net_profit', 'roe', 'net_margin',
        'revenue_growth_yoy', 'profit_growth_yoy'
    ])

    # Line chart
    fig = px.line(
        fa_df,
        x='report_date',
        y=metric,
        color='sector_code',
        title=f"{metric} Over Time"
    )
    st.plotly_chart(fig, use_container_width=True)

with tab3:
    st.header("Valuation Analysis")

    # Load TA data
    ta_df = service.get_ta_metrics(
        start_date=str(date_range[0]),
        end_date=str(date_range[1])
    )

    if selected_sectors:
        ta_df = ta_df[ta_df['sector_code'].isin(selected_sectors)]

    # Historical PE chart
    st.subheader("Historical PE")
    fig = px.line(
        ta_df,
        x='date',
        y='sector_pe',
        color='sector_code',
        title="Sector PE Over Time"
    )
    st.plotly_chart(fig, use_container_width=True)

    # Candlestick distribution (latest)
    st.subheader("Valuation Distribution (Latest)")
    latest_ta = service.get_latest_ta_snapshot()
    if selected_sectors:
        latest_ta = latest_ta[latest_ta['sector_code'].isin(selected_sectors)]

    # Box plot style chart
    fig = go.Figure()
    for _, row in latest_ta.iterrows():
        fig.add_trace(go.Box(
            x=[row['sector_code']],
            q1=[row['pe_q25']],
            median=[row['pe_median']],
            q3=[row['pe_q75']],
            lowerfence=[row['pe_min']],
            upperfence=[row['pe_max']],
            name=row['sector_code']
        ))

    fig.update_layout(title="PE Distribution by Sector", showlegend=False)
    st.plotly_chart(fig, use_container_width=True)

with tab4:
    st.header("Signals")

    # Signals table
    signals_df = combined_df[[
        'sector_code', 'signal', 'signal_strength',
        'signal_reason', 'combined_score'
    ]].sort_values('combined_score', ascending=False)

    st.dataframe(signals_df, use_container_width=True)

    # Heatmap of scores
    st.subheader("Score Heatmap")
    heatmap_data = combined_df.pivot_table(
        index='sector_code',
        values=['fa_total_score', 'ta_total_score', 'combined_score']
    )

    fig = px.imshow(
        heatmap_data.T,
        labels=dict(x="Sector", y="Score Type", color="Score"),
        title="Score Heatmap"
    )
    st.plotly_chart(fig, use_container_width=True)
```

---

## üßÆ Calculation Formulas

### 7.1 FA Formulas / C√¥ng Th·ª©c Ph√¢n T√≠ch C∆° B·∫£n

**Principle:** Sum-Aggregation First, Ratio-Calculation Second

#### A. Absolute Metrics (Aggregation)

```python
# General formula
Sector_Metric = Œ£(Company_i_Metric) for all companies in sector

# Examples
Sector_Revenue = Company_A_Revenue + Company_B_Revenue + ... + Company_N_Revenue
Sector_Net_Profit = Œ£(Net_Profit_i)
Sector_Total_Assets = Œ£(Total_Assets_i)
Sector_Total_Equity = Œ£(Total_Equity_i)
```

#### B. Ratio Metrics (Derived from Aggregates)

```python
# ROE (Return on Equity)
Sector_ROE = Sector_Net_Profit / Sector_Total_Equity

# Net Margin
Sector_Net_Margin = Sector_Net_Profit / Sector_Revenue

# ROA (Return on Assets)
Sector_ROA = Sector_Net_Profit / Sector_Total_Assets

# Debt to Equity
Sector_Debt_to_Equity = Sector_Total_Liabilities / Sector_Total_Equity
```

#### C. Growth Rates (YoY, QoQ)

```python
# YoY Growth (Year-over-Year)
Sector_Revenue_Growth_YoY = (
    (Sector_Revenue_Q_t - Sector_Revenue_Q_t-4) / Sector_Revenue_Q_t-4
)

# QoQ Growth (Quarter-over-Quarter)
Sector_Revenue_Growth_QoQ = (
    (Sector_Revenue_Q_t - Sector_Revenue_Q_t-1) / Sector_Revenue_Q_t-1
)
```

#### D. Bank-Specific Formulas

```python
# 1. Size (Quy m√¥)
Sector_Total_Assets = Œ£(Total_Assets_i)
Sector_Total_Credit = Œ£(Total_Credit_i) # Loans + Bonds
Sector_Total_Customer_Loans = Œ£(Customer_Loans_i)
Sector_Total_Customer_Deposits = Œ£(Customer_Deposits_i)

# 2. Income Statement (K·∫øt qu·∫£ kinh doanh)
Sector_NII = Œ£(NII_i)
Sector_TOI = Œ£(TOI_i)
Sector_NOII = Sector_TOI - Sector_NII
Sector_OPEX = Œ£(OPEX_i)
Sector_PPOP = Œ£(PPOP_i)
Sector_Provision_Expenses = Œ£(Provision_Expenses_i)
Sector_PBT = Œ£(PBT_i)
Sector_NPATMI = Œ£(NPATMI_i)

# 3. Growth (TƒÉng tr∆∞·ªüng - YoY/QoQ)
Sector_Credit_Growth = (Sector_Total_Credit_t - Sector_Total_Credit_t-1) / Sector_Total_Credit_t-1
Sector_Asset_Growth = (Sector_Total_Assets_t - Sector_Total_Assets_t-1) / Sector_Total_Assets_t-1
Sector_NII_Growth = (Sector_NII_t - Sector_NII_t-1) / Sector_NII_t-1
Sector_TOI_Growth = (Sector_TOI_t - Sector_TOI_t-1) / Sector_TOI_t-1
Sector_PBT_Growth = (Sector_PBT_t - Sector_PBT_t-1) / Sector_PBT_t-1
Sector_NPATMI_Growth = (Sector_NPATMI_t - Sector_NPATMI_t-1) / Sector_NPATMI_t-1

# 4. Asset Quality (Ch·∫•t l∆∞·ª£ng t√†i s·∫£n)
Sector_NPL_Ratio = Sector_Total_Bad_Debt / Sector_Total_Customer_Loans
Sector_LLCR = Sector_Total_Provisions / Sector_Total_Bad_Debt
Sector_Credit_Cost = Sector_Provision_Expenses / Sector_Avg_Customer_Loans * 100
# Note: Formation rates require delta calculation of NPLs which is complex for agg level, skipping for now provided simpler metrics.

# 5. Capital Adequacy (An to√†n v·ªën)
Sector_LDR = Sector_Total_Customer_Loans / Sector_Total_Customer_Deposits
Sector_CASA_Ratio = Sector_CASA_Deposits / Sector_Total_Deposits
Sector_Leverage = Sector_Total_Assets / Sector_Total_Equity
Sector_Net_Interbank_Ratio = Sector_Net_Interbank / Sector_Total_Customer_Deposits

# 6. Earning Quality (Ch·∫•t l∆∞·ª£ng l·ª£i nhu·∫≠n)
# Yields (Annualized usually, but here based on quarterly sums requiring TTM or annualized logic in implementation)
Sector_Loan_Yield = Sector_Interest_Income_Loans / Sector_Avg_Customer_Loans
Sector_Funding_Cost = Sector_Interest_Expenses / Sector_Avg_Interest_Bearing_Liabilities
Sector_NIM = Sector_NII / Sector_Avg_Interest_Earning_Assets
Sector_CIR = Sector_OPEX / Sector_TOI
Sector_Provision_to_PPOP = Sector_Provision_Expenses / Sector_PPOP
```


#### E. Security-Specific Formulas

```python
# 1. Scale (Quy M√¥)
Sector_Total_Assets = Œ£(Total_Assets_i)
Sector_Total_Equity = Œ£(Total_Equity_i)
Sector_Total_Investment = Œ£(Total_Investment_i) # FVTPL + HTM + AFS
Sector_Total_Margin_Loans = Œ£(Margin_Loans_i)
Sector_Total_Debt = Œ£(Total_Debt_i)

# 2. Income (K·∫øt Qu·∫£ Kinh Doanh)
Sector_Total_Revenue = Œ£(Total_Revenue_i)
Sector_Gross_Profit = Œ£(Gross_Profit_i)
Sector_Income_FVTPL = Œ£(FVTPL_Income_i)
Sector_Income_HTM = Œ£(HTM_Income_i)
Sector_Income_Loans = Œ£(Margin_Income_i)
Sector_NPATMI = Œ£(NPATMI_i)

# 3. Ratios (Hi·ªáu Qu·∫£ & An To√†n)
Sector_Leverage = Sector_Total_Assets / Sector_Total_Equity
Sector_Loans_to_Equity = Sector_Total_Margin_Loans / Sector_Total_Equity
Sector_Inv_to_Assets = Sector_Total_Investment / Sector_Total_Assets
Sector_Loans_to_Assets = Sector_Total_Margin_Loans / Sector_Total_Assets

# 4. Profitability (TTM/Annualized)
Sector_ROAE = Sector_NPATMI / Sector_Avg_Equity
Sector_ROAA = Sector_NPATMI / Sector_Avg_Assets
Sector_Inv_Yield = (Sector_Income_FVTPL + Sector_Income_HTM) / Sector_Avg_Investment
Sector_Loan_Yield = Sector_Income_Loans / Sector_Avg_Margin_Loans
```


#### F. Company-Specific Formulas (Non-Financial)

```python
# Gross Margin
Sector_Gross_Margin = Sector_Gross_Profit / Sector_Net_Revenue

# Operating Margin (EBIT Margin)
Sector_Operating_Margin = Sector_Operating_Profit / Sector_Net_Revenue

# Efficiency (SG&A Ratio)
Sector_SGA_Ratio = Sector_SGA_Expenses / Sector_Net_Revenue

# Depreciation & Investment
Sector_Accumulated_Depreciation_Rate = Sector_Accumulated_Depreciation / Sector_Gross_Fixed_Assets
Sector_CIP_Ratio = Sector_Construction_In_Progress / Sector_Total_Assets

# EBITDA Margin (Optional - if EBITDA available)
Sector_EBITDA_Margin = Sector_EBITDA / Sector_Net_Revenue
Sector_EBIT_Margin = Sector_EBIT / Sector_Net_Revenue

# Where:
#   Sector_Gross_Profit = Œ£(Gross_Profit_i)
#   Sector_Operating_Profit = Œ£(Operating_Profit_i)
#   Sector_SGA_Expenses = Œ£(Selling_Exp_i + Admin_Exp_i)
```

### 7.2 TA Formulas / C√¥ng Th·ª©c ƒê·ªãnh Gi√°

**Principle:** Market-Cap Weighted Aggregation

#### A. Sector Valuation Multiples

```python
# Sector Value & Volume
Sector_Trading_Value = Œ£(Volume_i * Close_Price_i)
Sector_Total_Volume = Œ£(Volume_i)

# Sector PE (Price-to-Earnings)
Sector_PE = Œ£(Market_Cap_i) / Œ£(TTM_Earnings_i)

# Where:
#   Market_Cap_i = Current market capitalization of stock i
#   TTM_Earnings_i = Trailing 12-month earnings

# Sector PB (Price-to-Book)
Sector_PB = Œ£(Market_Cap_i) / Œ£(Book_Value_i)

# Sector PS (Price-to-Sales)
Sector_PS = Œ£(Market_Cap_i) / Œ£(TTM_Revenue_i)

# Sector EV/EBITDA
Sector_EV_EBITDA = Œ£(Enterprise_Value_i) / Œ£(EBITDA_i)

# Where:
#   Enterprise_Value = Market_Cap + Total_Debt - Cash
```

#### B. Cross-Sectional Distribution

```python
# At each date, for all stocks in sector:
PE_Median = median([PE_1, PE_2, ..., PE_N])
PE_Q25 = 25th percentile of PE values
PE_Q75 = 75th percentile of PE values
PE_Min = min(PE values)
PE_Max = max(PE values)
PE_Mean = mean(PE values)
PE_Std = standard_deviation(PE values)
```

#### C. Historical Percentile

```python
# Where does current PE sit in 5-year history?
PE_Percentile_5Y = (
    Count(Historical_PE < Current_PE) / Total_Historical_Days * 100
)

# Example:
# If current PE = 15.0
# 5Y historical PE range: [8.0, 20.0]
# Historical days where PE < 15.0: 630 days
# Total 5Y days: 1260 days
# PE_Percentile_5Y = 630 / 1260 * 100 = 50% (median)
```

### 7.3 Scoring Formulas / C√¥ng Th·ª©c T√≠nh ƒêi·ªÉm

#### A. FA Scoring

**Component Scores (0-100):**

```python
# Growth Score
def calculate_growth_score(revenue_growth_yoy, profit_growth_yoy, thresholds):
    """
    Score based on YoY growth rates

    Thresholds:
        excellent: 20%
        good: 10%
        neutral: 5%
        poor: 0%
    """
    revenue_score = map_to_score(revenue_growth_yoy, thresholds)
    profit_score = map_to_score(profit_growth_yoy, thresholds)

    # Weighted average (profit more important)
    growth_score = revenue_score * 0.4 + profit_score * 0.6

    return growth_score

# Profitability Score
def calculate_profitability_score(roe, net_margin, roa, thresholds):
    """Score based on profitability metrics"""
    roe_score = map_to_score(roe, thresholds['roe'])
    margin_score = map_to_score(net_margin, thresholds['net_margin'])
    roa_score = map_to_score(roa, thresholds['roa'])

    # Weighted average
    prof_score = (
        roe_score * 0.5 +
        margin_score * 0.3 +
        roa_score * 0.2
    )

    return prof_score

# Helper function
def map_to_score(value, thresholds):
    """
    Map value to 0-100 score using thresholds

    Example thresholds:
        excellent: 0.20
        good: 0.15
        neutral: 0.10
        poor: 0.05
    """
    if value >= thresholds['excellent']:
        return 100
    elif value >= thresholds['good']:
        return 75
    elif value >= thresholds['neutral']:
        return 50
    elif value >= thresholds['poor']:
        return 25
    else:
        return 0
```

**FA Total Score:**

```python
# Apply component weights
FA_Total_Score = (
    Growth_Score * 0.3 +
    Profitability_Score * 0.4 +
    Efficiency_Score * 0.2 +
    Financial_Health_Score * 0.1
)

# Range: 0-100
```

#### B. TA Scoring

```python
# Valuation Score (based on percentile)
def calculate_valuation_score(pe_percentile_5y, pb_percentile_5y):
    """
    Lower percentile = Cheaper = Higher score

    Logic:
        Percentile 0-10%: Very cheap ‚Üí 100 points
        Percentile 10-25%: Cheap ‚Üí 75 points
        Percentile 25-75%: Fair ‚Üí 50 points
        Percentile 75-90%: Expensive ‚Üí 25 points
        Percentile 90-100%: Very expensive ‚Üí 0 points
    """
    pe_score = 100 - pe_percentile_5y  # Invert (lower is better)
    pb_score = 100 - pb_percentile_5y

    # Average
    valuation_score = (pe_score + pb_score) / 2

    return valuation_score

# Momentum Score
def calculate_momentum_score(price_change_20d, volume_ratio):
    """
    Score based on price momentum and volume

    price_change_20d: % change over 20 days
    volume_ratio: Current volume / 20D average
    """
    # Price momentum component
    if price_change_20d > 0.10:  # >10%
        price_score = 100
    elif price_change_20d > 0.05:  # >5%
        price_score = 75
    elif price_change_20d > 0:
        price_score = 50
    else:
        price_score = 25

    # Volume component
    if volume_ratio > 1.5:  # 50% above average
        volume_score = 100
    elif volume_ratio > 1.2:
        volume_score = 75
    elif volume_ratio > 0.8:
        volume_score = 50
    else:
        volume_score = 25

    # Weighted average
    momentum_score = price_score * 0.6 + volume_score * 0.4

    return momentum_score

# TA Total Score
TA_Total_Score = (
    Valuation_Score * 0.5 +
    Momentum_Score * 0.3 +
    Breadth_Score * 0.2
)
```

#### C. Combined Score

```python
# Apply FA/TA weights
Combined_Score = (
    FA_Total_Score * FA_Weight +
    TA_Total_Score * TA_Weight
)

# Default weights: FA=0.6, TA=0.4
# Range: 0-100

# Example:
# FA_Total_Score = 75
# TA_Total_Score = 60
# FA_Weight = 0.6, TA_Weight = 0.4
# Combined_Score = 75 * 0.6 + 60 * 0.4 = 45 + 24 = 69
```

#### D. Signal Generation

```python
def generate_signal(combined_score, thresholds):
    """
    Generate BUY/HOLD/SELL signal

    Thresholds:
        buy: 70
        sell: 30
    """
    if combined_score >= thresholds['buy']:
        signal = "BUY"
        strength = int((combined_score - 70) / 6) + 1  # 1-5
    elif combined_score <= thresholds['sell']:
        signal = "SELL"
        strength = int((30 - combined_score) / 6) + 1  # 1-5
    else:
        signal = "HOLD"
        strength = 1

    # Clamp strength to 1-5
    strength = max(1, min(5, strength))

    return signal, strength

# Signal reasons
def explain_signal(sector, fa_score, ta_score, combined_score, signal):
    """Generate human-readable explanation"""
    reasons = []

    if fa_score > 75:
        reasons.append("Strong fundamentals")
    elif fa_score < 40:
        reasons.append("Weak fundamentals")

    if ta_score > 75:
        reasons.append("Attractive valuation")
    elif ta_score < 40:
        reasons.append("Expensive valuation")

    if signal == "BUY":
        return f"{sector}: {', '.join(reasons)}. Combined score: {combined_score:.1f}"
    elif signal == "SELL":
        return f"{sector}: {', '.join(reasons)}. Combined score: {combined_score:.1f}"
    else:
        return f"{sector}: Neutral. Combined score: {combined_score:.1f}"
```

---

## üìÅ File Structure

### 8.1 Complete Directory Tree

```
Vietnam_dashboard/
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ registries/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metric_lookup.py                   # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sector_lookup.py                   # ‚úÖ Exists
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ sector_analysis/                       # ‚ùå CREATE NEW
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ default_config.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sector_specific_config.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scoring_thresholds.json
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metric_registry.json               # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ schema_registry.py                     # ‚úÖ Exists
‚îÇ   ‚îî‚îÄ‚îÄ unit_standards.json                    # ‚úÖ Exists
‚îÇ
‚îú‚îÄ‚îÄ DATA/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fundamental/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ company/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ company_financial_metrics.parquet   # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bank/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bank_financial_metrics.parquet      # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ security_financial_metrics.parquet  # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ insurance/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ insurance_financial_metrics.parquet # ‚ö†Ô∏è Need to create
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ technical/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ basic_data.parquet             # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ valuation/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pe/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pe_historical.parquet      # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pe_latest.parquet          # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pb/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pb_historical.parquet      # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pb_latest.parquet          # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sector_pe/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sector_pe_historical.parquet   # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ sector_pe_latest.parquet       # ‚úÖ Exists
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sector/                            # ‚ö†Ô∏è UPDATE
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sector_fundamental_metrics.parquet     # ‚ö†Ô∏è Needs update
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sector_valuation_metrics.parquet       # ‚ö†Ô∏è Needs update
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ sector_combined_scores.parquet         # ‚ùå CREATE NEW
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ raw/
‚îÇ       ‚îî‚îÄ‚îÄ ...                                 # ‚úÖ Exists
‚îÇ
‚îú‚îÄ‚îÄ PROCESSORS/
‚îÇ   ‚îú‚îÄ‚îÄ fundamental/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ calculators/                       # ‚úÖ Exists
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ company_calculator.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ bank_calculator.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ valuation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ calculators/                       # ‚úÖ Exists
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ sector/                                # ‚ùå CREATE NEW
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ calculators/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ base_aggregator.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fa_aggregator.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ta_aggregator.py
‚îÇ       ‚îú‚îÄ‚îÄ scoring/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ fa_scorer.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ ta_scorer.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ signal_generator.py
‚îÇ       ‚îú‚îÄ‚îÄ sector_processor.py
‚îÇ       ‚îî‚îÄ‚îÄ run_sector_analysis.py
‚îÇ
‚îî‚îÄ‚îÄ WEBAPP/
    ‚îú‚îÄ‚îÄ services/
    ‚îÇ   ‚îú‚îÄ‚îÄ sector_service.py                  # ‚ùå CREATE NEW
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îÇ
    ‚îî‚îÄ‚îÄ pages/
        ‚îú‚îÄ‚îÄ sector_analysis_dashboard.py       # ‚ùå CREATE NEW
        ‚îú‚îÄ‚îÄ valuation_sector_dashboard.py      # ‚ö†Ô∏è Exists (PE only)
        ‚îî‚îÄ‚îÄ ...
```

### 8.2 File Creation Checklist

**Status Legend:**
- ‚úÖ Exists and ready
- ‚ö†Ô∏è Exists but needs update
- ‚ùå Needs to be created

| File | Status | Priority | LOC Est. |
|------|--------|----------|----------|
| **CONFIG** |
| `config/sector_analysis/config_manager.py` | ‚ùå | HIGH | 200 |
| `config/sector_analysis/default_config.json` | ‚ùå | HIGH | 50 |
| `config/sector_analysis/sector_specific_config.json` | ‚ùå | MEDIUM | 100 |
| `config/sector_analysis/scoring_thresholds.json` | ‚ùå | MEDIUM | 80 |
| **PROCESSORS** |
| `PROCESSORS/sector/calculators/fa_aggregator.py` | ‚ùå | HIGH | 400 |
| `PROCESSORS/sector/calculators/ta_aggregator.py` | ‚ùå | HIGH | 350 |
| `PROCESSORS/sector/calculators/base_aggregator.py` | ‚ùå | MEDIUM | 150 |
| `PROCESSORS/sector/scoring/fa_scorer.py` | ‚ùå | MEDIUM | 300 |
| `PROCESSORS/sector/scoring/ta_scorer.py` | ‚ùå | MEDIUM | 250 |
| `PROCESSORS/sector/scoring/signal_generator.py` | ‚ùå | MEDIUM | 200 |
| `PROCESSORS/sector/sector_processor.py` | ‚ùå | HIGH | 300 |
| `PROCESSORS/sector/run_sector_analysis.py` | ‚ùå | LOW | 100 |
| **WEBAPP** |
| `WEBAPP/services/sector_service.py` | ‚ùå | HIGH | 250 |
| `WEBAPP/pages/sector_analysis_dashboard.py` | ‚ùå | HIGH | 500 |
| **DATA** |
| `DATA/processed/fundamental/insurance/*.parquet` | ‚ö†Ô∏è | LOW | N/A |
| `DATA/processed/sector/sector_fundamental_metrics.parquet` | ‚ö†Ô∏è | HIGH | N/A |
| `DATA/processed/sector/sector_valuation_metrics.parquet` | ‚ö†Ô∏è | HIGH | N/A |
| `DATA/processed/sector/sector_combined_scores.parquet` | ‚ùå | HIGH | N/A |

**Total New Code Estimate:** ~2,500-3,000 lines of Python

---

## üöÄ Implementation Roadmap

### Phase 0: Preparation (1 day)

**Checklist:**
- [ ] Review all existing data files
- [ ] Verify SectorRegistry has all 19 sectors mapped
- [ ] Verify MetricRegistry has all required metrics
- [ ] Create `PROCESSORS/sector/` directory structure
- [ ] Create `config/sector_analysis/` directory structure

**Deliverables:**
- Directory structure created
- Dependencies verified

---

### Phase 1: Configuration System (2-3 days)

**Checklist:**
- [ ] Create `config/sector_analysis/config_manager.py`
- [ ] Create `config/sector_analysis/default_config.json`
- [ ] Create `config/sector_analysis/sector_specific_config.json`
- [ ] Create `config/sector_analysis/scoring_thresholds.json`
- [ ] Write unit tests for ConfigManager
- [ ] Document configuration options

**Deliverables:**
- ConfigManager class (200 LOC)
- 3 JSON config files
- Unit tests
- Documentation in `config/sector_analysis/README.md`

**Testing:**
```python
from config.sector_analysis import ConfigManager

config = ConfigManager()
weights = config.get_fa_ta_weights("Banking")
assert weights['fa_weight'] == 0.7  # Bank-specific override
```

---

### Phase 2: FA Aggregator (3-4 days)

**Checklist:**
- [ ] Create `PROCESSORS/sector/calculators/base_aggregator.py`
- [ ] Create `PROCESSORS/sector/calculators/fa_aggregator.py`
- [ ] Implement data loading (company/bank/security/insurance)
- [ ] Implement sector mapping (using SectorRegistry)
- [ ] Implement sum aggregation (absolute metrics)
- [ ] Implement ratio calculation (from aggregates)
- [ ] Implement growth calculation (YoY, QoQ)
- [ ] Handle bank-specific metrics (NIM, NPL, LDR)
- [ ] Handle security-specific metrics
- [ ] Write unit tests
- [ ] Test with real data

**Deliverables:**
- `fa_aggregator.py` (400 LOC)
- `base_aggregator.py` (150 LOC)
- Unit tests
- Sample output: `sector_fundamental_metrics.parquet`

**Testing:**
```python
from PROCESSORS.sector.calculators import FAAggregator

agg = FAAggregator(config, sector_reg, metric_reg)
result = agg.aggregate_sector_fundamentals()

# Verify output schema
assert 'sector_code' in result.columns
assert 'total_revenue' in result.columns
assert 'roe' in result.columns

# Verify calculations
banking_sector = result[result['sector_code'] == 'Banking'].iloc[0]
assert banking_sector['roe'] == banking_sector['net_profit'] / banking_sector['total_equity']
```

---

### Phase 3: TA Aggregator (3-4 days)

**Checklist:**
- [ ] Create `PROCESSORS/sector/calculators/ta_aggregator.py`
- [ ] Load market data (OHLCV, market cap)
- [ ] Load existing PE/PB data
- [ ] Implement sector PE/PB/PS calculation (market-cap weighted)
- [ ] Implement cross-sectional distribution (percentiles)
- [ ] Implement historical percentile calculation (5Y rolling)
- [ ] Handle data quality (filter invalid data)
- [ ] Write unit tests
- [ ] Test with real data

**Deliverables:**
- `ta_aggregator.py` (350 LOC)
- Unit tests
- Sample output: `sector_valuation_metrics.parquet`

**Testing:**
```python
from PROCESSORS.sector.calculators import TAAggregator

agg = TAAggregator(config, sector_reg)
result = agg.aggregate_sector_valuation()

# Verify output schema
assert 'sector_pe' in result.columns
assert 'pe_percentile_5y' in result.columns

# Verify calculation
banking_val = result[result['sector_code'] == 'Banking'].iloc[0]
assert 0 <= banking_val['pe_percentile_5y'] <= 100
```

---

### Phase 4: Scoring & Signals (3-4 days)

**Checklist:**
- [ ] Create `PROCESSORS/sector/scoring/fa_scorer.py`
- [ ] Create `PROCESSORS/sector/scoring/ta_scorer.py`
- [ ] Create `PROCESSORS/sector/scoring/signal_generator.py`
- [ ] Implement FA scoring (growth, profitability, efficiency, health)
- [ ] Implement TA scoring (valuation, momentum, breadth)
- [ ] Implement signal generation (BUY/HOLD/SELL)
- [ ] Implement signal strength (1-5)
- [ ] Implement signal explanations
- [ ] Write unit tests
- [ ] Test with real data

**Deliverables:**
- `fa_scorer.py` (300 LOC)
- `ta_scorer.py` (250 LOC)
- `signal_generator.py` (200 LOC)
- Unit tests

**Testing:**
```python
from PROCESSORS.sector.scoring import FAScorer, TAScorer, SignalGenerator

fa_scorer = FAScorer(config)
fa_scores = fa_scorer.calculate_scores(fa_df)

# Verify scores are 0-100
assert (fa_scores['fa_total_score'] >= 0).all()
assert (fa_scores['fa_total_score'] <= 100).all()

# Test signal generation
signal_gen = SignalGenerator(config)
with_signals = signal_gen.generate_signals(combined_df)

assert 'signal' in with_signals.columns
assert set(with_signals['signal'].unique()).issubset({'BUY', 'HOLD', 'SELL'})
```

---

### Phase 5: Sector Processor (2-3 days)

**Checklist:**
- [ ] Create `PROCESSORS/sector/sector_processor.py`
- [ ] Create `PROCESSORS/sector/run_sector_analysis.py`
- [ ] Implement orchestration logic
- [ ] Implement FA + TA combination
- [ ] Implement output saving (3 parquet files)
- [ ] Add logging and progress tracking
- [ ] Add error handling
- [ ] Write integration tests
- [ ] Test full pipeline end-to-end

**Deliverables:**
- `sector_processor.py` (300 LOC)
- `run_sector_analysis.py` (100 LOC)
- Integration tests
- All 3 output files generated

**Testing:**
```bash
# Run full pipeline
python3 PROCESSORS/sector/run_sector_analysis.py

# Verify outputs
ls -lh DATA/processed/sector/
# Should see:
#   sector_fundamental_metrics.parquet
#   sector_valuation_metrics.parquet
#   sector_combined_scores.parquet
```

---

### Phase 6: Sector Service (2 days)

**Checklist:**
- [ ] Create `WEBAPP/services/sector_service.py`
- [ ] Implement data loading with caching
- [ ] Implement filtering (sector, date range)
- [ ] Implement formatting helpers
- [ ] Implement sector metadata access
- [ ] Write unit tests
- [ ] Test with Streamlit

**Deliverables:**
- `sector_service.py` (250 LOC)
- Unit tests
- API documentation

**Testing:**
```python
from WEBAPP.services.sector_service import SectorService

service = SectorService()

# Test FA data access
fa_data = service.get_fa_metrics(sector="Banking")
assert not fa_data.empty
assert 'total_revenue' in fa_data.columns

# Test TA data access
ta_data = service.get_ta_metrics(sector="Banking")
assert 'sector_pe' in ta_data.columns

# Test combined scores
combined = service.get_combined_scores()
assert 'combined_score' in combined.columns
```

---

### Phase 7: Streamlit Dashboard (4-5 days)

**Checklist:**
- [ ] Create `WEBAPP/pages/sector_analysis_dashboard.py`
- [ ] Implement sidebar filters (sector, date, weights)
- [ ] Implement Overview tab (table, bar chart)
- [ ] Implement Fundamental tab (FA metrics, charts)
- [ ] Implement Valuation tab (PE/PB charts, distribution)
- [ ] Implement Signals tab (signals table, heatmap)
- [ ] Add formatting using SchemaRegistry
- [ ] Add caching for performance
- [ ] Test UI/UX
- [ ] Write user documentation

**Deliverables:**
- `sector_analysis_dashboard.py` (500 LOC)
- User guide
- Screenshots

**Testing:**
```bash
# Run Streamlit app
streamlit run WEBAPP/main_app.py

# Manual testing:
# 1. Navigate to Sector Analysis page
# 2. Select multiple sectors
# 3. Change date range
# 4. Verify charts render correctly
# 5. Verify data formatting (VND, %, ratios)
# 6. Test interactivity (hover, click)
```

---

### Phase 8: Testing & Validation (2-3 days)

**Checklist:**
- [ ] Run all unit tests
- [ ] Run integration tests
- [ ] Validate FA aggregation (spot check calculations)
- [ ] Validate TA aggregation (compare with existing sector_pe)
- [ ] Validate scoring logic (check thresholds)
- [ ] Validate signals (review Buy/Sell recommendations)
- [ ] Performance testing (processing time)
- [ ] Data quality checks
- [ ] Create validation report

**Deliverables:**
- Test results report
- Validation report (spot checks)
- Performance benchmarks

**Validation Checklist:**

**FA Validation:**
```python
# Spot check Banking sector
banking_fa = fa_df[fa_df['sector_code'] == 'Banking'].iloc[0]

# Manual calculation
bank_data = bank_df[bank_df['symbol'].isin(banking_tickers)]
manual_total_revenue = bank_data['total_revenue'].sum()

# Compare
assert abs(banking_fa['total_revenue'] - manual_total_revenue) < 1e6  # Allow rounding
```

**TA Validation:**
```python
# Compare with existing sector PE calculator
existing_pe = pd.read_parquet("DATA/processed/valuation/sector_pe/sector_pe_latest.parquet")
new_pe = ta_df[ta_df['sector_code'] == 'Banking']

# Should match within 1%
assert abs(existing_pe['sector_pe'] - new_pe['sector_pe']) / existing_pe['sector_pe'] < 0.01
```

---

### Phase 9: Documentation (1-2 days)

**Checklist:**
- [ ] Write README for `PROCESSORS/sector/`
- [ ] Write README for `config/sector_analysis/`
- [ ] Update `WEBAPP/pages/README.md`
- [ ] Write user guide for dashboard
- [ ] Create formula reference document
- [ ] Add docstrings (bilingual) to all classes/functions
- [ ] Create troubleshooting guide
- [ ] Update main project documentation

**Deliverables:**
- `PROCESSORS/sector/README.md`
- `config/sector_analysis/README.md`
- User guide (PDF or MD)
- Formula reference document
- Updated project docs

---

### Timeline Summary

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| Phase 0: Preparation | 1 day | None |
| Phase 1: Configuration | 2-3 days | Phase 0 |
| Phase 2: FA Aggregator | 3-4 days | Phase 1 |
| Phase 3: TA Aggregator | 3-4 days | Phase 1 |
| Phase 4: Scoring | 3-4 days | Phase 2, 3 |
| Phase 5: Processor | 2-3 days | Phase 4 |
| Phase 6: Service | 2 days | Phase 5 |
| Phase 7: Dashboard | 4-5 days | Phase 6 |
| Phase 8: Testing | 2-3 days | Phase 7 |
| Phase 9: Documentation | 1-2 days | Phase 8 |

**Total Estimated Time:** 23-31 days (~4-6 weeks for 1 developer)

**Parallel Work Opportunities:**
- Phase 2 and Phase 3 can be done in parallel (FA and TA aggregators)
- Phase 6 and Phase 7 can overlap (service development while building UI)

---

## ‚úÖ Testing & Validation

### 10.1 Unit Test Structure

```
tests/
‚îî‚îÄ‚îÄ sector/
    ‚îú‚îÄ‚îÄ test_config_manager.py
    ‚îú‚îÄ‚îÄ test_fa_aggregator.py
    ‚îú‚îÄ‚îÄ test_ta_aggregator.py
    ‚îú‚îÄ‚îÄ test_fa_scorer.py
    ‚îú‚îÄ‚îÄ test_ta_scorer.py
    ‚îú‚îÄ‚îÄ test_signal_generator.py
    ‚îú‚îÄ‚îÄ test_sector_processor.py
    ‚îî‚îÄ‚îÄ test_sector_service.py
```

### 10.2 Key Test Cases

#### A. FA Aggregator Tests

```python
def test_sum_aggregation():
    """Test that absolute metrics are summed correctly"""
    # Mock data
    company_data = pd.DataFrame({
        'symbol': ['A', 'B', 'C'],
        'sector': ['Tech', 'Tech', 'Tech'],
        'total_revenue': [100e9, 200e9, 300e9]
    })

    result = aggregator.aggregate_sector(company_data, 'Tech')

    expected_revenue = 600e9  # 100 + 200 + 300
    assert result['total_revenue'] == expected_revenue

def test_ratio_calculation():
    """Test that ratios are calculated from aggregates, not averaged"""
    # Mock aggregated data
    sector_data = {
        'net_profit': 100e9,
        'total_equity': 500e9
    }

    roe = sector_data['net_profit'] / sector_data['total_equity']

    assert roe == 0.2  # 20%

def test_growth_calculation():
    """Test YoY growth calculation"""
    # Time series data
    ts_data = pd.DataFrame({
        'sector': ['Tech'] * 8,
        'report_date': pd.date_range('2023-Q1', periods=8, freq='Q'),
        'total_revenue': [100, 110, 120, 130, 140, 150, 160, 170]
    })

    result = aggregator._calculate_growth(ts_data)

    # Q1 2024 vs Q1 2023: (140 - 100) / 100 = 0.4
    q1_2024_growth = result[result['report_date'] == '2024-03-31']['revenue_growth_yoy'].iloc[0]
    assert abs(q1_2024_growth - 0.4) < 0.01

def test_bank_specific_metrics():
    """Test bank-specific calculations (NIM, NPL, LDR)"""
    bank_data = {
        'nii': 50e9,
        'interest_earning_assets': 1000e9,
        'bad_debt': 20e9,
        'total_loans': 800e9,
        'customer_loans': 700e9,
        'customer_deposits': 600e9
    }

    nim = bank_data['nii'] / bank_data['interest_earning_assets']
    npl_ratio = bank_data['bad_debt'] / bank_data['total_loans']
    ldr = bank_data['customer_loans'] / bank_data['customer_deposits']

    assert abs(nim - 0.05) < 0.001  # 5%
    assert abs(npl_ratio - 0.025) < 0.001  # 2.5%
    assert abs(ldr - 1.1667) < 0.01  # 116.67%
```

#### B. TA Aggregator Tests

```python
def test_sector_pe_calculation():
    """Test sector PE = Sum(Market Cap) / Sum(Earnings)"""
    market_data = pd.DataFrame({
        'symbol': ['A', 'B', 'C'],
        'market_cap': [1000e9, 2000e9, 1500e9],
        'ttm_earnings': [100e9, 150e9, 120e9]
    })

    total_mcap = market_data['market_cap'].sum()  # 4500e9
    total_earnings = market_data['ttm_earnings'].sum()  # 370e9
    sector_pe = total_mcap / total_earnings  # 12.16

    assert abs(sector_pe - 12.16) < 0.01

def test_percentile_calculation():
    """Test historical percentile calculation"""
    # 5 years of daily PE data
    historical_pe = pd.Series([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
    current_pe = 15

    percentile = (historical_pe < current_pe).sum() / len(historical_pe) * 100

    assert percentile == 50.0  # 15 is median

def test_cross_sectional_distribution():
    """Test quartile calculation"""
    pe_values = pd.Series([8, 10, 12, 14, 16, 18, 20, 22, 24])

    q25 = pe_values.quantile(0.25)
    median = pe_values.quantile(0.5)
    q75 = pe_values.quantile(0.75)

    assert q25 == 11
    assert median == 16
    assert q75 == 21
```

#### C. Scoring Tests

```python
def test_fa_scoring():
    """Test FA score calculation"""
    fa_data = {
        'revenue_growth_yoy': 0.15,  # 15% ‚Üí Good ‚Üí 75 points
        'roe': 0.20,  # 20% ‚Üí Excellent ‚Üí 100 points
        'net_margin': 0.12,  # 12% ‚Üí Good ‚Üí 75 points
        'debt_to_equity': 0.8  # Good ‚Üí 75 points
    }

    scorer = FAScorer(config)
    score = scorer.calculate_scores(pd.DataFrame([fa_data]))

    # Expected: weighted average based on component weights
    assert 60 <= score['fa_total_score'].iloc[0] <= 90

def test_signal_generation():
    """Test signal logic"""
    # High combined score ‚Üí BUY
    assert generate_signal(75, thresholds={'buy': 70, 'sell': 30}) == ("BUY", 1)

    # Low combined score ‚Üí SELL
    assert generate_signal(25, thresholds={'buy': 70, 'sell': 30}) == ("SELL", 1)

    # Middle score ‚Üí HOLD
    assert generate_signal(50, thresholds={'buy': 70, 'sell': 30})[0] == "HOLD"
```

### 10.3 Integration Tests

```python
def test_full_pipeline():
    """Test complete pipeline end-to-end"""
    processor = SectorProcessor()

    # Run pipeline
    results = processor.run_full_pipeline()

    # Verify outputs exist
    assert (processor.output_dir / "sector_fundamental_metrics.parquet").exists()
    assert (processor.output_dir / "sector_valuation_metrics.parquet").exists()
    assert (processor.output_dir / "sector_combined_scores.parquet").exists()

    # Verify data quality
    fa_df = results['fa_df']
    assert not fa_df.empty
    assert fa_df['roe'].notna().sum() > 0

    ta_df = results['ta_df']
    assert not ta_df.empty
    assert ta_df['sector_pe'].notna().sum() > 0

    combined_df = results['combined_df']
    assert 'signal' in combined_df.columns
    assert combined_df['combined_score'].between(0, 100).all()

def test_data_consistency():
    """Test data consistency between components"""
    # FA and TA should have matching sectors
    fa_df = pd.read_parquet("DATA/processed/sector/sector_fundamental_metrics.parquet")
    ta_df = pd.read_parquet("DATA/processed/sector/sector_valuation_metrics.parquet")

    fa_sectors = set(fa_df['sector_code'].unique())
    ta_sectors = set(ta_df['sector_code'].unique())

    # Should have significant overlap (may not be 100% due to data availability)
    overlap = len(fa_sectors & ta_sectors)
    assert overlap >= 15  # At least 15 sectors in common
```

### 10.4 Validation Checklist

**Manual Spot Checks:**

```python
# Banking Sector Validation
banking_fa = fa_df[fa_df['sector_code'] == 'Banking'].iloc[-1]

# Get all bank tickers
bank_tickers = sector_reg.get_tickers_by_sector('Banking')

# Load individual bank data
bank_individual = bank_df[bank_df['symbol'].isin(bank_tickers)]
latest_quarter = bank_individual['report_date'].max()
bank_latest = bank_individual[bank_individual['report_date'] == latest_quarter]

# Validate sum aggregation
manual_total_assets = bank_latest['total_assets'].sum()
sector_total_assets = banking_fa['total_assets']

print(f"Manual sum: {manual_total_assets:,.0f}")
print(f"Sector agg: {sector_total_assets:,.0f}")
print(f"Difference: {abs(manual_total_assets - sector_total_assets):,.0f}")
assert abs(manual_total_assets - sector_total_assets) < 1e9  # Allow 1B VND difference

# Validate ratio calculation
manual_roe = bank_latest['net_profit'].sum() / bank_latest['total_equity'].sum()
sector_roe = banking_fa['roe']

print(f"Manual ROE: {manual_roe:.4f}")
print(f"Sector ROE: {sector_roe:.4f}")
assert abs(manual_roe - sector_roe) < 0.001  # Allow 0.1% difference
```

**Performance Benchmarks:**

```python
import time

# FA Aggregation
start = time.time()
fa_df = fa_agg.aggregate_sector_fundamentals()
fa_time = time.time() - start
print(f"FA Aggregation: {fa_time:.2f}s")
assert fa_time < 60  # Should complete in <60s

# TA Aggregation
start = time.time()
ta_df = ta_agg.aggregate_sector_valuation()
ta_time = time.time() - start
print(f"TA Aggregation: {ta_time:.2f}s")
assert ta_time < 120  # Should complete in <120s

# Full Pipeline
start = time.time()
processor.run_full_pipeline()
total_time = time.time() - start
print(f"Full Pipeline: {total_time:.2f}s")
assert total_time < 300  # Should complete in <5 minutes
```

---

## üìù Appendix

### A. Sector List (19 Sectors)

Based on `SectorRegistry`:

1. Banking (Ng√¢n h√†ng) - 24 tickers
2. Securities (Ch·ª©ng kho√°n) - 37 tickers
3. Insurance (B·∫£o hi·ªÉm) - 6 tickers
4. Real Estate (B·∫•t ƒë·ªông s·∫£n) - ~50 tickers
5. Construction (X√¢y d·ª±ng) - ~40 tickers
6. Steel (Th√©p) - ~15 tickers
7. Oil & Gas (D·∫ßu kh√≠) - ~10 tickers
8. Retail (B√°n l·∫ª) - ~30 tickers
9. Food & Beverage (Th·ª±c ph·∫©m ƒë·ªì u·ªëng) - ~25 tickers
10. Textiles (D·ªát may) - ~20 tickers
11. Chemicals (H√≥a ch·∫•t) - ~15 tickers
12. Technology (C√¥ng ngh·ªá) - ~10 tickers
13. Transportation (V·∫≠n t·∫£i) - ~20 tickers
14. Telecommunications (Vi·ªÖn th√¥ng) - ~5 tickers
15. Utilities (ƒêi·ªán n∆∞·ªõc) - ~15 tickers
16. Healthcare (Y t·∫ø) - ~10 tickers
17. Agriculture (N√¥ng nghi·ªáp) - ~25 tickers
18. Mining (Khai kho√°ng) - ~10 tickers
19. Others (Kh√°c) - ~70 tickers

**Total:** 457 tickers

### B. Metric Code Examples

From `MetricRegistry` (2,099 metrics):

**Income Statement:**
- `CIS_1`: Doanh thu thu·∫ßn (Net Revenue)
- `CIS_12`: L·ª£i nhu·∫≠n sau thu·∫ø (Net Profit After Tax)
- `CIS_62`: Chi ph√≠ qu·∫£n l√Ω doanh nghi·ªáp (SG&A)

**Balance Sheet:**
- `CBS_14`: T·ªïng t√†i s·∫£n (Total Assets)
- `CBS_31`: V·ªën ch·ªß s·ªü h·ªØu (Total Equity)
- `CBS_100`: T·ªïng n·ª£ (Total Liabilities)

**Bank-Specific:**
- `BBS_24`: Cho vay kh√°ch h√†ng (Customer Loans)
- `BBS_90`: Ti·ªÅn g·ª≠i kh√°ch h√†ng (Customer Deposits)
- `BIS_11`: Thu nh·∫≠p l√£i thu·∫ßn (NII)

**Security-Specific:**
- `SBS_22`: Cho vay margin (Margin Loans)
- `SBS_15`: T√†i s·∫£n FVTPL (FVTPL Assets)
- `SIS_16`: Doanh thu m√¥i gi·ªõi (Brokerage Revenue)

### C. Reference Documents

1. **Architecture:**
   - `config/README.md` - Configuration system guide
   - `PROCESSORS/fundamental/calculators/README.md` - Calculator documentation
   - `CLAUDE.md` - Project instructions

2. **Data Standards:**
   - `config/unit_standards.json` - v4.0.0 unit standardization
   - `config/metadata/metric_registry.json` - Metric definitions

3. **Existing Implementations:**
   - `PROCESSORS/valuation/calculators/vnindex_pe_calculator_optimized.py` - PE calculation reference
   - `WEBAPP/pages/valuation_sector_dashboard.py` - Existing sector PE dashboard
   - `WEBAPP/pages/bank_dashboard.py` - Bank dashboard (candlestick reference)

---

## üéØ Success Criteria

### Functional Requirements

‚úÖ **Complete** when all of these are true:

1. **FA Aggregation:**
   - [ ] All 19 sectors have FA metrics calculated
   - [ ] Calculations follow sum-aggregation principle
   - [ ] Bank/Security-specific metrics handled correctly
   - [ ] Growth rates (YoY, QoQ) calculated accurately
   - [ ] Output matches schema specification

2. **TA Aggregation:**
   - [ ] Sector PE/PB/PS calculated (market-cap weighted)
   - [ ] Historical percentiles calculated (5Y rolling)
   - [ ] Cross-sectional distribution calculated
   - [ ] Output matches schema specification

3. **Scoring & Signals:**
   - [ ] FA scores calculated (0-100 range)
   - [ ] TA scores calculated (0-100 range)
   - [ ] Combined scores use configurable weights
   - [ ] Signals generated (BUY/HOLD/SELL)
   - [ ] Signal explanations provided

4. **Configuration:**
   - [ ] ConfigManager loads all settings
   - [ ] Default config works
   - [ ] Sector-specific overrides work
   - [ ] FA/TA weights adjustable

5. **Streamlit Dashboard:**
   - [ ] All 4 tabs functional (Overview, FA, TA, Signals)
   - [ ] Filters work (sector, date, weights)
   - [ ] Charts render correctly
   - [ ] Data formatted correctly (VND, %, ratios)
   - [ ] Performance acceptable (<3s load time)

6. **Data Quality:**
   - [ ] No missing sectors (all 19 present)
   - [ ] Latest data available (within 1 week)
   - [ ] Calculations verified (spot checks pass)
   - [ ] No data corruption

### Non-Functional Requirements

1. **Performance:**
   - [ ] FA aggregation: <60s
   - [ ] TA aggregation: <120s
   - [ ] Full pipeline: <5 minutes
   - [ ] Dashboard load: <3s

2. **Code Quality:**
   - [ ] All functions have docstrings (bilingual)
   - [ ] Unit test coverage >80%
   - [ ] Integration tests pass
   - [ ] No linting errors

3. **Documentation:**
   - [ ] README files complete
   - [ ] User guide written
   - [ ] Formula reference documented
   - [ ] Code comments adequate

4. **Maintainability:**
   - [ ] Code follows v4.0.0 architecture
   - [ ] Uses config/ as single source of truth
   - [ ] Uses SectorRegistry for mapping
   - [ ] Uses SchemaRegistry for formatting

---

## üìû Contact & Support

**For questions about this plan:**
- Review: `sector_plan.md` (original draft)
- Review: `CLAUDE.md` (project instructions)
- Review: `config/README.md` (configuration guide)

**For implementation:**
- Start with Phase 0 (Preparation)
- Follow phases sequentially
- Test after each phase
- Update this document as needed

---

## üìù Implementation Progress Log

**Implementation Started:** 2025-12-15
**Last Updated:** 2025-12-15

### ‚úÖ Phase 0: Preparation - COMPLETED

**Date:** 2025-12-15

**Verification Results:**

1. **‚úÖ SectorRegistry Verified**
   - Total sectors: 19
   - Total tickers: 457
   - Status: Production ready
   - Location: `config/registries/sector_lookup.py`

2. **‚úÖ MetricRegistry Verified**
   - Total metrics: 2,099 (COMPANY: 440, BANK: 476, INSURANCE: 439, SECURITY: 744)
   - Version: 1.0
   - Last updated: 2025-12-11T23:38:48
   - Status: Production ready
   - Location: `DATA/metadata/metric_registry.json`

3. **‚úÖ Existing Data Files Reviewed**
   - Fundamental data:
     - `company_financial_metrics.parquet` (1.5M)
     - `bank_financial_metrics.parquet` (182K)
     - `security_financial_metrics.parquet` (272K)
     - `insurance_financial_metrics.parquet` (16K)
   - Valuation data:
     - `historical_pe.parquet` (10M)
     - `historical_pb.parquet` (10M)
     - `historical_ev_ebitda.parquet` (12M)
     - `sector_valuation.parquet` (956K)
   - Existing sector files (partial):
     - `sector_fundamental_metrics.parquet` (55K) - needs update
     - `sector_valuation_metrics.parquet` (3.2M) - wrong format

**Status:** ‚úÖ COMPLETED

---

### ‚úÖ Phase 1: Configuration System - COMPLETED

**Date:** 2025-12-15

**Files Created:**

1. **‚úÖ config/sector_analysis/default_config.json**
   - FA/TA weights: 60/40 default
   - Component weights for FA and TA
   - Signal thresholds: BUY (70), SELL (30)
   - Lookback periods configuration

2. **‚úÖ config/sector_analysis/sector_specific_config.json**
   - Banking sector: FA 70%, TA 30%
   - Technology sector: FA 50%, TA 50%
   - Real Estate sector overrides

3. **‚úÖ config/sector_analysis/scoring_thresholds.json**
   - Growth thresholds (revenue, profit YoY)
   - Profitability thresholds (ROE, net margin, ROA)
   - Efficiency thresholds (asset turnover)
   - Financial health thresholds (debt-to-equity)
   - Valuation percentile bands
   - Momentum thresholds

4. **‚úÖ config/sector_analysis/config_manager.py**
   - Already existed, verified working

**Status:** ‚úÖ COMPLETED

---

### ‚úÖ Phase 2: FA Aggregator - COMPLETED

**Date:** 2025-12-15

**Files Created:**

1. **‚úÖ PROCESSORS/sector/calculators/base_aggregator.py** (200+ LOC)
   - BaseAggregator class with common utilities
   - Sector mapping helper (_add_sector_mapping)
   - Data loading helper (_load_parquet)
   - Date filtering (_filter_by_date)
   - Safe aggregation (_safe_sum)
   - Output saving (_save_output)

2. **‚úÖ PROCESSORS/sector/calculators/fa_aggregator.py** (732 LOC)
   - FAAggregator class inheriting from BaseAggregator
   - Loads all 4 entity types (company, bank, security, insurance)
   - Aggregates 37 fundamental metrics by sector
   - Calculates sector-level ratios (ROE, ROA, margins)
   - Bank-specific metrics (NIM, NII, NPL, LDR, CASA)
   - Security-specific metrics (margin loans, FVTPL)
   - YoY and QoQ growth calculations
   - Data quality scoring

3. **‚úÖ PROCESSORS/sector/calculators/__init__.py**
   - Exports BaseAggregator and FAAggregator

**Output Generated:**

- **DATA/processed/sector/sector_fundamental_metrics.parquet**
  - 589 rows (19 sectors √ó 31 quarters)
  - 37 metrics columns
  - Date range: 2018-Q1 to 2025-Q3
  - 100% data quality score

**Testing Results:**
- ‚úÖ All 19 sectors aggregated successfully
- ‚úÖ Banking sector: 24 tickers, NIM=4.22%, NII=148.4T VND
- ‚úÖ Security sector: 32 tickers, margin loans=181.1T VND
- ‚úÖ Growth calculations verified (YoY, QoQ)

**Status:** ‚úÖ COMPLETED

---

---

### ‚úÖ Phase 3: TA Aggregator - COMPLETED

**Date:** 2025-12-15

**Files Created:**

1. **‚úÖ PROCESSORS/sector/calculators/ta_aggregator.py** (651 LOC)
   - TAAggregator class inheriting from BaseAggregator
   - Market-cap weighted sector valuation multiples (PE, PB, PS, EV/EBITDA)
   - Cross-sectional distribution statistics (median, mean, std, quartiles)
   - Historical percentile calculation (5-year rolling window)
   - Integration with existing valuation data
   - Robust data handling for missing/invalid values

2. **‚úÖ PROCESSORS/sector/calculators/__init__.py** (updated)
   - Added TAAggregator export

**Output Generated:**

- **DATA/processed/sector/sector_valuation_metrics.parquet**
  - 4,712 rows (19 sectors √ó 248 trading days)
  - 28 metrics columns
  - Date range: 2024-12-16 to 2025-12-12
  - Data completeness: PE/PB 100%, EV/EBITDA 84.2%

**Testing Results:**
- ‚úÖ All 19 sectors aggregated successfully
- ‚úÖ Banking sector: PE=9.85, PB=1.62, PE percentile (5Y)=37.1%
- ‚úÖ Market-cap weighting verified
- ‚úÖ Historical percentiles calculated correctly

**Status:** ‚úÖ COMPLETED

---

---

### ‚úÖ Phase 4: Scoring & Signal Generation - COMPLETED

**Date:** 2025-12-15

**Files Created:**

1. **‚úÖ PROCESSORS/sector/scoring/fa_scorer.py** (556 LOC)
   - FAScorer class for fundamental analysis scoring
   - 4 scoring components: Growth (30%), Profitability (40%), Efficiency (20%), Financial Health (10%)
   - Uses thresholds from scoring_thresholds.json
   - Scores 0-100 scale with weighted aggregation
   - Tested: 589 records scored, avg score 54.37

2. **‚úÖ PROCESSORS/sector/scoring/ta_scorer.py** (529 LOC)
   - TAScorer class for technical/valuation scoring
   - 3 scoring components: Valuation (50%), Momentum (30%), Breadth (20%)
   - Inverse scoring for valuation (low percentile = high score)
   - Market-cap weighted sector strength
   - Tested: 4,712 records scored, avg score 59.43

3. **‚úÖ PROCESSORS/sector/scoring/signal_generator.py** (511 LOC)
   - SignalGenerator class for FA+TA combination
   - Generates BUY (>=70), HOLD (30-70), SELL (<=30) signals
   - Signal strength: 1-5 stars based on score ranges
   - Sector-specific FA/TA weights support
   - Bilingual signal explanations
   - Tested: 76 signals generated

4. **‚úÖ PROCESSORS/sector/scoring/__init__.py** (updated)
   - Exports FAScorer, TAScorer, SignalGenerator

**Testing Results:**
- ‚úÖ All scoring components working correctly
- ‚úÖ Threshold-based scoring verified
- ‚úÖ Signal generation logic tested
- ‚úÖ Full workflow: FA scoring ‚Üí TA scoring ‚Üí Signal generation

**Status:** ‚úÖ COMPLETED

---

---

### ‚úÖ Phase 5: Sector Processor Orchestrator - COMPLETED

**Date:** 2025-12-15

**Files Created:**

1. **‚úÖ PROCESSORS/sector/sector_processor.py** (467 LOC)
   - SectorProcessor class - main orchestrator
   - ConfigManager temporary implementation
   - run_full_pipeline() method with 6 steps
   - Progress tracking and error handling
   - Date range filtering support

2. **‚úÖ PROCESSORS/sector/run_sector_analysis.py** (312 LOC)
   - Complete CLI with argparse
   - Arguments: --start-date, --end-date, --report-date, --verbose, --output-dir
   - Date validation and error handling
   - Summary statistics and signal distribution reporting

**Pipeline Output:**

- **sector_fundamental_metrics.parquet** (30 KB, 133 records)
- **sector_valuation_metrics.parquet** (1.6 MB, 9,234 records)
- **sector_combined_scores.parquet** (23 KB, 95 signals)

**Test Results:**
- ‚úÖ Full pipeline runs successfully
- ‚úÖ FA Aggregation: 133 records (19 sectors √ó 7 quarters)
- ‚úÖ TA Aggregation: 9,234 records (19 sectors √ó 486 days)
- ‚úÖ FA Scoring: Avg score 55.5
- ‚úÖ TA Scoring: Avg score 58.4
- ‚úÖ Signals: 94 HOLD, 1 BUY

**Status:** ‚úÖ COMPLETED

---

### ‚ö†Ô∏è Phase 5.5: Bug Fixes & Enhancements - IN PROGRESS

**Issue #1: Missing Margin Metrics for Company Entities**

**Problem:** FA Aggregator (`fa_aggregator.py`) missing EBIT and EBITDA calculations for company entities before aggregation.

**Current Status:**
- ‚úÖ Has: gross_margin, operating_margin, net_margin (calculated from sector aggregates)
- ‚ùå Missing: EBIT, EBITDA, ebit_margin, ebitda_margin (required for proper company sector analysis)

**Required Formulas (from sector_plan.md Section 6.4):**

**Company Sector Metrics:**
```python
# Absolute values (sum from individual companies)
sector_ebit = sum(company_operating_profit)  # EBIT = Operating Profit
sector_ebitda = sum(company_ebitda)  # Need to calculate from company data

# Margins (calculated from sector aggregates)
ebit_margin = sector_ebit / sector_total_revenue
ebitda_margin = sector_ebitda / sector_total_revenue
gross_margin = sector_gross_profit / sector_total_revenue  # ‚úÖ Already exists
operating_margin = sector_operating_profit / sector_total_revenue  # ‚úÖ Already exists
net_margin = sector_net_profit / sector_total_revenue  # ‚úÖ Already exists

# Efficiency
sga_ratio = sector_sga / sector_total_revenue
```

**Bank Sector Metrics (Need to Verify):**
```python
# Already implemented:
nim_q = sector_nii / sector_interest_earning_assets  # ‚úÖ
npl_ratio = sector_npl_amount / sector_customer_loans  # ‚úÖ
ldr = sector_customer_loans / sector_customer_deposits  # ‚úÖ

# May need to add:
cir = sector_operating_expenses / sector_total_revenue  # Cost-to-Income Ratio
casa_ratio = sector_casa / sector_customer_deposits  # If CASA data available
```

**Securities Sector Metrics (Need to Add):**
```python
# Current implementation:
margin_loans = sum(company_margin_loans)  # ‚úÖ
fvtpl_assets = sum(company_fvtpl_assets)  # ‚úÖ
total_investment = sum(company_total_investment)  # ‚úÖ

# Missing:
leverage_ratio = sector_total_assets / sector_total_equity
loan_yield = sector_margin_income / avg_margin_loans  # Need margin_income data
investment_yield = sector_prop_trading_income / avg_fvtpl_assets  # Need prop trading income
```

**Action Items:**
- [ ] Review company financial data columns to identify available fields
- [ ] Add EBIT calculation (= operating_profit, already in data)
- [ ] Add EBITDA calculation (need depreciation/amortization data OR estimate)
- [ ] Add ebit_margin, ebitda_margin to _calculate_ratios()
- [ ] Add SG&A ratio if data available
- [ ] Add Bank CIR and CASA ratio if data available
- [ ] Add Securities leverage and yield ratios
- [ ] Re-run pipeline and verify all metrics
- [ ] Update documentation

**Status:** ‚ö†Ô∏è IN PROGRESS

---

**Next Steps:**
- Complete Phase 5.5: Fix FA Aggregator margin metrics
- Phase 6: Create Sector Service for WEBAPP
- Phase 7: Create Streamlit Dashboard
- Phase 8: Testing & Validation
- Phase 9: Documentation

---

**END OF SECTOR_PLAN_FINAL.MD**

*Generated: 2025-12-14*
*Version: 1.0.0*
*Status: Ready for Implementation*
*Implementation Started: 2025-12-15*

---

## üîß Phase 5.5 (REVISED): FA Aggregator Rewrite for Sector Calculation

**Date Started:** 2025-12-15  
**Status:** üìù REQUIREMENTS DOCUMENTED ‚Üí Ready for Implementation

### **Problem Statement**

**Current Issue:**
- FA Aggregator uses `*_financial_metrics.parquet` (individual stock calculations)
- Company data only has Balance Sheet ‚Üí **14/19 sectors have revenue=0**
- **Root Cause:** Individual calculators are for per-stock analysis, NOT sector aggregation

**Solution:**
- Rewrite FA Aggregator to use `*_full.parquet` (raw metric_code format)
- Build sector-specific formulas (sum-based aggregation)
- Follow specifications from `formula_migration_plan.md`

### **Architecture Change**

**Before (WRONG for Sector):**
```
company_calculator.py ‚Üí company_financial_metrics.parquet (per stock)
                     ‚Üì
              FA Aggregator (just sum columns)
                     ‚Üì
              Sector metrics (INCOMPLETE - revenue=0!)
```

**After (CORRECT for Sector):**
```
company_full.parquet (raw metric_code: CIS_10, CBS_300, etc.)
                     ‚Üì
         FA Aggregator v2.0 (sector-specific logic)
              1. Pivot metric codes to columns
              2. Map codes to business metrics
              3. Sum by sector (using SectorRegistry)
              4. Calculate sector ratios
                     ‚Üì
         Sector metrics (COMPLETE - all data!)
```

### **Data Sources**

**Input Files:**
- `DATA/processed/fundamental/company_full.parquet` (5.2M rows, 390 tickers)
- `DATA/processed/fundamental/bank_full.parquet`
- `DATA/processed/fundamental/security_full.parquet`
- `DATA/processed/fundamental/insurance_full.parquet`

**Format:**
| SECURITY_CODE | REPORT_DATE | METRIC_CODE | METRIC_VALUE | ENTITY_TYPE |
|---------------|-------------|-------------|--------------|-------------|
| HPG           | 2024-09-30  | CIS_10      | 50000000000  | COMPANY     |
| HPG           | 2024-09-30  | CBS_300     | 100000000000 | COMPANY     |
| ACB           | 2024-09-30  | BIS_3       | 15000000000  | BANK        |

### **Metric Code Mappings**

**Company Metrics (Source: formula_migration_plan.md):**
```python
COMPANY_INCOME_STATEMENT = {
    'CIS_10': 'net_revenue',          # Doanh thu thu·∫ßn
    'CIS_20': 'gross_profit',         # L·ª£i nhu·∫≠n g·ªôp  
    'CIS_40': 'cogs',                 # Gi√° v·ªën h√†ng b√°n
    'CIS_50': 'operating_profit',     # L·ª£i nhu·∫≠n t·ª´ HƒêKD
    'CIS_62': 'npatmi',               # L·ª£i nhu·∫≠n sau thu·∫ø
    # EBIT = operating_profit (CIS_50)
    # EBITDA = need depreciation data or estimate
}

COMPANY_BALANCE_SHEET = {
    'CBS_300': 'total_assets',
    'CBS_400': 'total_equity', 
    'CBS_500': 'total_liabilities',
    'CBS_100': 'current_assets',
    'CBS_200': 'long_term_assets',
}

# Sector formulas:
sector_gross_margin = sum(CIS_20) / sum(CIS_10)
sector_ebit_margin = sum(CIS_50) / sum(CIS_10)
sector_net_margin = sum(CIS_62) / sum(CIS_10)
sector_roe = sum(CIS_62) / sum(CBS_400)
```

**Bank Metrics (Source: formula_migration_plan.md:438-504):**
```python
BANK_SIZE = {
    'BBS_300': 'total_assets',
    'BBS_161': 'customer_loans',      # T·ªïng d∆∞ n·ª£ cho vay
    'BBS_330': 'customer_deposits',   # Ti·ªÅn g·ª≠i KH
}

BANK_INCOME = {
    'BIS_3': 'nii',                   # Thu nh·∫≠p l√£i thu·∫ßn
    'BIS_14A': 'toi',                 # T·ªïng thu nh·∫≠p Hƒê
    'BIS_14': 'opex',                 # Chi ph√≠ Hƒê (s·ªë √¢m)
    'BIS_16': 'provision_expenses',   # Chi ph√≠ d·ª± ph√≤ng
    'BIS_22A': 'npatmi',
}

BANK_ASSET_QUALITY = {
    'BNOT_4_3': 'npl_group3',
    'BNOT_4_4': 'npl_group4', 
    'BNOT_4_5': 'npl_group5',
    'BBS_169': 'loan_loss_provision',
}

# Sector formulas:
sector_nim = sum(BIS_3) / sum(interest_earning_assets)
sector_npl = (sum(BNOT_4_3) + sum(BNOT_4_4) + sum(BNOT_4_5)) / sum(BBS_161)
sector_ldr = sum(BBS_161) / sum(BBS_330)
sector_cir = abs(sum(BIS_14)) / sum(BIS_14A)
```

**Security Metrics (Source: formula_migration_plan.md:509-535):**
```python
SECURITY_SCALE = {
    'SBS_270': 'total_assets',
    'SBS_400': 'total_equity',
    'SBS_114': 'margin_loans',        # Cho vay margin
    'SBS_112': 'fvtpl_securities',    # CK FVTPL
    'SBS_113': 'htm_securities',      # CK HTM
    'SBS_115': 'afs_securities',      # CK AFS
}

SECURITY_INCOME = {
    'SIS_20': 'total_revenue',
    'SIS_1': 'income_from_fvtpl',
    'SIS_2': 'income_from_htm',
    'SIS_3': 'income_from_loans',
    'SIS_201': 'npatmi',
}

# Sector formulas:
sector_leverage = sum(SBS_270) / sum(SBS_400)
sector_total_investment = sum(SBS_112 + SBS_113 + SBS_115)
sector_loan_yield = sum(SIS_3, TTM) / avg(SBS_114)
sector_inv_yield = sum(SIS_1, TTM) / avg(SBS_112)
```

### **Implementation Components**

**File 1:** `PROCESSORS/sector/calculators/metric_mappings.py` (NEW)
```python
# Centralized metric code mappings for all entity types
COMPANY_MAPPINGS = {...}
BANK_MAPPINGS = {...}  
SECURITY_MAPPINGS = {...}
INSURANCE_MAPPINGS = {...}
```

**File 2:** `PROCESSORS/sector/calculators/fa_aggregator.py` (REWRITE)
```python
class FAAggregator:
    def _load_and_pivot_company_data(self, company_full_df):
        """Pivot metric_code to columns"""
        # Transform from long to wide format
        # Apply COMPANY_MAPPINGS
        
    def _aggregate_sector(self, entity_df, sector_code):
        """Sum metrics for one sector"""
        # Filter tickers in sector
        # Sum absolute metrics
        # Calculate ratios
        
    def aggregate_sector_fundamentals(self):
        """Main entry point"""
        # Load *_full.parquet
        # Pivot each entity type
        # Aggregate by sector
        # Combine all sectors
        # Calculate growth rates
```

**Estimated Size:** ~800-1000 lines total

### **Testing Checklist**

- [x] Verify all 19 sectors have revenue > 0
- [x] Verify company sectors: X√¢y d·ª±ng, B√°n l·∫ª, Th·ª±c ph·∫©m have complete data
- [x] Verify bank sector: NIM, NPL, LDR calculated correctly
- [x] Verify security sector: Leverage, Loan Yield calculated
- [x] Compare sector totals with market-wide aggregates
- [x] Check data quality scores
- [x] Verify growth calculations (YoY, QoQ)

### **Implementation Status**

- [x] Requirements documented
- [x] Data sources identified
- [x] Metric mappings specified
- [x] Create metric_mappings.py
- [x] Rewrite fa_aggregator.py
- [x] Unit tests
- [x] Integration test with full pipeline
- [x] Update sector_plan_final.md with results

### **Test Results (2025-12-15)**

**Pipeline Execution:** ‚úÖ SUCCESS (15 seconds)

**Data Quality Verification:**
```
Top 10 Sectors by Revenue (Q3 2025, Billions VND):
1. Ng√¢n h√†ng                   188,515.51B VND ‚úÖ
2. D·∫ßu kh√≠                     167,035.84B VND ‚úÖ
3. Th·ª±c ph·∫©m v√† ƒë·ªì u·ªëng         96,170.61B VND ‚úÖ (was 0 before!)
4. B·∫•t ƒë·ªông s·∫£n                 86,903.63B VND ‚úÖ
5. T√†i nguy√™n C∆° b·∫£n            85,929.47B VND ‚úÖ
6. B√°n l·∫ª                       70,688.66B VND ‚úÖ (was 0 before!)
7. ƒêi·ªán, n∆∞·ªõc & xƒÉng d·∫ßu kh√≠ ƒë·ªët 65,479.13B VND ‚úÖ
8. X√¢y d·ª±ng v√† V·∫≠t li·ªáu         57,281.24B VND ‚úÖ (was 0 before!)
9. Du l·ªãch v√† Gi·∫£i tr√≠          53,251.81B VND ‚úÖ
10. H√†ng & D·ªãch v·ª• C√¥ng nghi·ªáp  48,917.07B VND ‚úÖ

Sectors with ZERO revenue: 0/19 ‚úÖ
```

**Output Files Generated:**
- `sector_fundamental_metrics.parquet`: 133 records (19 sectors √ó 7 quarters)
- `sector_valuation_metrics.parquet`: 9,234 records (19 sectors √ó 486 days)
- `sector_combined_scores.parquet`: 95 signals (all HOLD, scores 30-70)

**FA Aggregator v2.0 Metrics:**
- Company: 11,320 rows, 390 tickers, 17 metrics ‚úÖ
- Bank: 744 rows, 24 tickers, 31 metrics ‚úÖ
- Security: 980 rows, 32 tickers, 20 metrics ‚úÖ
- Insurance: 186 rows, 6 tickers, 4 metrics ‚úÖ

**Key Improvements:**
1. ‚úÖ Fixed company sectors revenue=0 issue
2. ‚úÖ All entity types now use *_full.parquet files
3. ‚úÖ Metric code pivot transformation working correctly
4. ‚úÖ Sector-level formulas correctly aggregate sum-based metrics
5. ‚úÖ Bank-specific ratios (NIM, NPL, CASA) calculated
6. ‚úÖ Security-specific ratios (Leverage, Yields) calculated
7. ‚úÖ Growth rates (YoY, QoQ) computed

**Critical Success:** Company sectors (X√¢y d·ª±ng, B√°n l·∫ª, Th·ª±c ph·∫©m) now have complete fundamental data including revenue, gross margin, operating profit, and net profit.

---

