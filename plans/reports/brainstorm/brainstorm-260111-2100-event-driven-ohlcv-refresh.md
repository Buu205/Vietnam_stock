# Brainstorm: Event-Driven OHLCV Refresh Strategy

**Date:** 2026-01-11
**Topic:** Pre-OHLCV event check Ä‘á»ƒ refresh full data khi cÃ³ corporate events

---

## Problem Statement

Cáº§n thÃªm bÆ°á»›c kiá»ƒm tra TRÆ¯á»šC khi cháº¡y OHLCV update:
1. **Primary**: Check ngÃ y GDKHQ (giao dá»‹ch khÃ´ng hÆ°á»Ÿng quyá»n) tá»« Vietstock API
2. **Fallback 1**: Shares Outstanding thay Ä‘á»•i so vá»›i 5 phiÃªn liá»n ká»
3. **Fallback 2**: GiÃ¡ thay Ä‘á»•i >8% so vá»›i phiÃªn trÆ°á»›c

**Khi trigger**: Cháº¡y full OHLCV history refresh cho cÃ¡c mÃ£ affected

---

## Evaluated Approaches

### Option 1: Live API Check (Real-time)

```
Pipeline run â†’ Call Vietstock API â†’ Filter tickers â†’ Refresh affected
```

| Pros | Cons |
|------|------|
| Dá»¯ liá»‡u luÃ´n má»›i nháº¥t | Cháº­m (~5-10s API call) |
| KhÃ´ng cáº§n maintain cache | API cÃ³ thá»ƒ fail/rate limit |
| ÄÆ¡n giáº£n implement | Cookie/token cÃ³ thá»ƒ expire |

**Verdict**: âŒ KhÃ´ng khuyáº¿n khÃ­ch - dependency vÃ o external API má»—i láº§n cháº¡y

---

### Option 2: Event Parquet Cache (Pre-fetched)

```
Weekly job: Fetch events â†’ Save parquet
Pipeline run: Read parquet â†’ Filter â†’ Refresh affected
```

| Pros | Cons |
|------|------|
| Ráº¥t nhanh (~50ms Ä‘á»c file) | Cáº§n job riÃªng update |
| Offline-capable | CÃ³ thá»ƒ miss events má»›i |
| Stable, khÃ´ng API failures | ThÃªm 1 file cáº§n maintain |

**Schema Ä‘á» xuáº¥t:**
```python
# vietstock_events.parquet
{
    "ticker": str,           # VNM, VCB, ...
    "event_type": str,       # DIVIDEND_CASH, DIVIDEND_STOCK, RIGHTS_ISSUE
    "ex_date": date,         # NgÃ y GDKHQ (GDKHQDate)
    "record_date": date,     # NgÃ y Ä‘Äƒng kÃ½ cuá»‘i cÃ¹ng (NDKCCDate)
    "payment_date": date,    # NgÃ y thanh toÃ¡n (Time)
    "note": str,             # "Tráº£ cá»• tá»©c nÄƒm 2024 báº±ng tiá»n, 1000Ä‘/CP"
    "fetched_at": timestamp  # Timestamp láº¥y dá»¯ liá»‡u
}
```

**Verdict**: âš ï¸ OK nhÆ°ng thiáº¿u real-time cho events Ä‘á»™t xuáº¥t

---

### Option 3: Hybrid Strategy (Recommended) â­

```
1. Event parquet (refresh weekly/daily) â†’ Primary lookup
2. Price/Shares anomaly detection tá»« OHLCV data â†’ Fallback
3. Optional: Live API check náº¿u cáº§n
```

**Flow:**
```
OHLCV Update Pipeline
â”‚
â”œâ”€ Step 0 (NEW): Pre-check Module
â”‚   â”œâ”€ 0.1 Read events parquet â†’ Filter GDKHQ = today
â”‚   â”œâ”€ 0.2 Read existing OHLCV â†’ Detect anomalies
â”‚   â”‚       â””â”€ Shares changed vs last 5 days
â”‚   â”‚       â””â”€ Price moved >8%
â”‚   â””â”€ 0.3 Combine triggers â†’ List of tickers to refresh
â”‚
â”œâ”€ Step 1: OHLCV Update
â”‚   â”œâ”€ Normal update for non-affected tickers
â”‚   â””â”€ Full history refresh for affected tickers
â”‚
â””â”€ Step 2+: TA, Valuation, etc.
```

| Pros | Cons |
|------|------|
| Fast (file-based primary) | ThÃªm 1 module má»›i |
| Robust (multiple fallbacks) | Complexity tÄƒng nháº¹ |
| Offline-capable | Cáº§n 2 data sources |
| Self-healing via anomaly detection | - |

**Verdict**: âœ… RECOMMENDED

---

## Recommended Solution: Hybrid Strategy

### 1. New Module: `event_trigger_check.py`

**Location:** `PROCESSORS/pipelines/utils/event_trigger_check.py`

```python
def get_tickers_needing_full_refresh() -> list[str]:
    """
    Check multiple trigger conditions and return tickers needing full OHLCV refresh.

    Priority:
    1. Event calendar (GDKHQ = today)
    2. Shares outstanding anomaly (changed vs 5 days)
    3. Price anomaly (>8% move)
    """
    affected = set()

    # 1. Event-based (primary)
    events_df = load_events_cache()
    if events_df is not None:
        today_events = events_df[events_df['ex_date'] == today]
        affected.update(today_events['ticker'].tolist())

    # 2. Shares anomaly (fallback)
    shares_anomalies = detect_shares_changes()
    affected.update(shares_anomalies)

    # 3. Price anomaly (fallback)
    price_anomalies = detect_price_moves(threshold=0.08)
    affected.update(price_anomalies)

    return list(affected)
```

### 2. Event Cache Update Job

**Location:** `PROCESSORS/pipelines/utils/update_event_cache.py`

```python
# Cháº¡y riÃªng: daily hoáº·c weekly
# Output: DATA/processed/events/vietstock_events.parquet
```

**Khi nÃ o cháº¡y:**
- Cron: Daily lÃºc 7:00 AM (trÆ°á»›c market open)
- Manual: Khi cáº§n refresh

### 3. Pipeline Integration

**Modify:** `run_all_daily_updates.py`

```python
# Before OHLCV step
from PROCESSORS.pipelines.utils.event_trigger_check import get_tickers_needing_full_refresh

# Get tickers needing full refresh
full_refresh_tickers = get_tickers_needing_full_refresh()
if full_refresh_tickers:
    logger.info(f"ðŸ”„ {len(full_refresh_tickers)} tickers need full OHLCV refresh:")
    logger.info(f"   {full_refresh_tickers[:10]}...")  # Show first 10

    # Run full refresh for these tickers
    run_ohlcv_full_refresh(full_refresh_tickers)

# Then run normal daily update
run_script('daily_ohlcv_update.py', ...)
```

---

## Detection Logic Details

### 1. Event Detection (Primary)

```python
def filter_today_events(events_df: pd.DataFrame) -> list[str]:
    """Filter tickers with GDKHQ (ex-date) = today."""
    today = date.today()
    return events_df[events_df['ex_date'] == today]['ticker'].unique().tolist()
```

### 2. Shares Outstanding Anomaly

```python
def detect_shares_changes(ohlcv_df: pd.DataFrame, lookback: int = 5) -> list[str]:
    """Detect tickers where shares outstanding changed vs last 5 sessions."""
    anomalies = []

    for ticker in ohlcv_df['symbol'].unique():
        ticker_data = ohlcv_df[ohlcv_df['symbol'] == ticker].tail(lookback + 1)

        if len(ticker_data) < 2:
            continue

        # Compare latest vs previous sessions
        latest_shares = ticker_data.iloc[-1]['shareOutstanding']
        prev_shares = ticker_data.iloc[:-1]['shareOutstanding'].mode()[0]  # Most common

        if latest_shares != prev_shares:
            anomalies.append(ticker)

    return anomalies
```

### 3. Price Anomaly Detection

```python
def detect_price_moves(ohlcv_df: pd.DataFrame, threshold: float = 0.08) -> list[str]:
    """Detect tickers with >8% price move vs previous day."""
    anomalies = []

    for ticker in ohlcv_df['symbol'].unique():
        ticker_data = ohlcv_df[ohlcv_df['symbol'] == ticker].tail(2)

        if len(ticker_data) < 2:
            continue

        prev_close = ticker_data.iloc[-2]['close']
        curr_close = ticker_data.iloc[-1]['close']

        pct_change = abs(curr_close - prev_close) / prev_close

        if pct_change > threshold:
            anomalies.append(ticker)

    return anomalies
```

---

## Data File Structure

```
DATA/
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ events/
â”‚       â””â”€â”€ vietstock_events.parquet    # Event cache (NEW)
â”‚           Schema:
â”‚           - ticker: str
â”‚           - event_type: str
â”‚           - ex_date: date
â”‚           - record_date: date
â”‚           - payment_date: date
â”‚           - note: str
â”‚           - fetched_at: timestamp
â”‚
â””â”€â”€ raw/
    â””â”€â”€ ohlcv/
        â””â”€â”€ OHLCV_mktcap.parquet        # Existing OHLCV data
```

---

## Priority Order

| Priority | Trigger | Why |
|----------|---------|-----|
| 1 | Event calendar (GDKHQ) | Most reliable, known in advance |
| 2 | Shares changed | Corporate action indicator |
| 3 | Price >8% | Likely event, but could be market-driven |

---

## Performance Comparison

| Approach | Lookup Time | API Calls | Reliability |
|----------|-------------|-----------|-------------|
| Live API only | ~5-10s | Yes | Medium (API dependent) |
| Parquet only | ~50ms | No | High (local file) |
| **Hybrid** | ~100ms | Optional | Highest (fallbacks) |

---

## Implementation Considerations

### Risks
1. **Stale event cache**: Mitigate via daily refresh job
2. **False positives (price moves)**: Accept, better safe than miss event
3. **API token expiry**: Refresh mechanism needed

### Success Metrics
- Zero missed corporate events causing data gaps
- Pipeline runtime increase <30s
- Event cache freshness <24h

### Next Steps
1. Create `event_trigger_check.py` module
2. Create `update_event_cache.py` job
3. Integrate into `run_all_daily_updates.py`
4. Add cron for event cache refresh

---

## Recommended Answer to Original Question

> **"NÃªn táº¡o file parquet sá»± kiá»‡n hay nhÆ° tháº¿ nÃ o?"**

âœ… **NÃªn dÃ¹ng Hybrid approach:**
1. **Parquet event cache** - Primary, fast lookup
2. **Anomaly detection tá»« OHLCV** - Fallback, self-healing
3. **Æ¯u tiÃªn event calendar** - VÃ¬ Ä‘Ã£ biáº¿t trÆ°á»›c, chÃ­nh xÃ¡c nháº¥t

**LÃ½ do:**
- Event parquet: Tra cá»©u nhanh (~50ms vs ~5s API)
- Anomaly detection: Báº¯t Ä‘Æ°á»£c cases event cache miss
- KhÃ´ng phá»¥ thuá»™c 100% vÃ o external API khi cháº¡y pipeline

---

## Unresolved Questions

1. **Event cache refresh frequency?** Daily 7AM recommended
2. **Full refresh scope?** All history or just affected dates?
3. **Include other event types?** AGM, phÃ¡t hÃ nh má»›i, etc.?
